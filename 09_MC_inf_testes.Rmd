---
title: "Métodos de Monte Carlo em inferência estatística"
subtitle: "Testes de hipótese de Monte Carlo"
author: "Fernando P. Mayer"
bibliography: ref.bib
output:
  html_document:
    number_sections: true
    toc_depth: 3
---

```{r, cache=FALSE, include=FALSE}
source("setup_knitr.R")
opts_chunk$set(fig.path = "figures/09_MC_inf_testes/")
```

# Introdução

Besag e Clifford (1989) definiram que um teste de Monte Carlo
generalizado é um que possui as seguintes características:

1. Um conjunto de dados observado, é apenas um entre muitos conjuntos
   que poderiam ter ocorrido
2. Todos os possíveis conjuntos de dados podem ser gerados a partir de
   uma série de mudanças incrementais nos dados (**randomização**)
   - Aqui vamos assumir que todos os possíveis conjuntos de dados podem
     ser gerados a partir de algum modelo probabilístico (Monte Carlo)
3. A hipótese nula de interesse afirma que todos os possíveis conjuntos
   de dados possuem a mesma probabilidade de ocorrência
4. Todo conjunto de dados possível pode ser resumido por alguma
   estatística de teste $S$

- Um teste de hipótese consiste em calcular uma medida (**estatística de
  teste**) e verificar o quanto ela é provável dentro do cenário de
  ocorrências puramente ao acaso, **supondo que a hipótese nula é
  verdadeira**.
  - Se a conclusão for de que é um valor dos mais prováveis, então não
  existem evidências para rejeitar a hipótese nula.
  - Se for dos resultados mais extremos, então existem evidências de que
    a hipótese nula não é verdadeira

Partindo dessa ideia, um teste de hipótese de Monte Carlo pode ser
formulado da seguinte maneira:

1. Calcule a estatística de teste para a amostra
2. Supondo que a hipótese nula é verdadeira, simule valores com as
   mesmas características do modelo probabilístico sendo testado (sob
   $H_0$)
3. Repita o passo (2) um número $N$ grande de vezes, e calcule a
   estatística de teste em todos os passos
4. Com a distribuição dos $N$ valores da estatística de teste (supondo
   $H_0$) verdadeira, **calcule a proporção de valores iguais ou mais
   extremos** que a estatística de teste da amostra

- O último passo pode ser interpretado como o $p$-valor de Monte Carlo, ou
$p$-valor empírico.
  - Proporções altas mostram que a estatística de teste amostral não é
    tão extrema, o que favorece $H_0$
  - Proporções baixas indicam que a estatística de teste é extrema
    (pouca probabilidade de ocorrer simplesmente ao acaso), por isso a
    hipótese nula deve ser pouco plausível

# Procedimento padrão

#### Procedimentos gerais para um teste de hipótese {-}

1. Definir a hipótese nula ($H_0$) e a alternativa ($H_a$).
2. Definir um nível de significância $\alpha$, que irá determinar o
nível de confiança $100(1 - \alpha)$% do teste.
3. Definir o tipo de teste, com base na hipótese alternativa.
4. Calcular a estatística de teste, com base na distribuição amostral
do estimador do parâmetro sob teste $\rightarrow$ valor calculado.
5. Determinar a região crítica (região de rejeição), com base no nível.
de significância $\alpha$ $\rightarrow$ valor crítico.
6. Concluir o teste.

#### Erros de decisão {-}

Para entendermos o que é o nível de significância $(\alpha)$, precisamos
saber que, ao realizar um teste de hipótese, estamos sujeitos a dois
tipos de erros.

- **Erro Tipo I**: rejeitar $H_0$, quando $H_0$ é
verdadeira (falso negativo).
- **Erro Tipo II**: não rejeitar $H_0$, quando $H_0$ é falsa (falso positivo).

|                    | $H_0$ verdadeira | $H_0$ falsa     |
| :--------          | :----------:     | :-------------: |
| Não rejeitar $H_0$ | Decisão correta  | Erro tipo II    |
| Rejeitar $H_0$     | Erro tipo I      | Decisão correta |

Definimos por $\alpha$ e $\beta$ as probabilidades de cometer os erros
do tipo I e II:

- $\alpha = \text{P}(\text{erro tipo I}) =
\text{P}(\text{rejeitar } H_0 \, | \, H_0 \text{ verdadeira})$.
- $\beta = \text{P}(\text{erro tipo II}) =
\text{P}(\text{não rejeitar } H_0 \, | \, H_0 \text{ falsa})$.
   - $\alpha$ é o **nível de significância** do teste.
   - $1 - \alpha$ é o **nível de confiança** do teste.

#### Nível descritivo {-}

- Em geral, $\alpha$ é pré-fixado para construir a regra de decisão.
- Uma alternativa é deixar em aberto a escolha de $\alpha$ para quem for
tomar a decisão.
- A ideia é calcular, **supondo que a hipótese nula é verdadeira**, a
probabilidade de se obter estimativas **iguais ou mais extremas do que
aquela fornecida pela amostra**.
- Essa probabilidade é chamada de **nível descritivo**, denotada por
$\alpha^*$ (ou $p$-valor).
- Valores pequenos de $\alpha^*$ evidenciam que a hipótese nula é falsa.
- O conceito de "pequeno" fica para quem decide qual $\alpha$ deve usar
para comparar com $\alpha^*$.

Para **testes unilaterais**, sendo $H_0: \mu = \mu_0$, a expressão de
$\alpha^*$ depende da hipótese alternativa:

\begin{align*}
\alpha^* &= P(\bar{X} < \bar{x}_{obs} \, | \, H_0 \text{ verdadeira}) \quad
\text{para } H_a: \mu < \mu_0 \\
\alpha^* &= P(\bar{X} > \bar{x}_{obs} \, | \, H_0 \text{ verdadeira}) \quad
\text{para } H_a: \mu > \mu_0
\end{align*}

Para **testes bilaterais**, temos $H_0: \mu = \mu_0$ contra $H_0: \mu
\neq \mu_0$, a definição do nível descritivo depende da relação entre
$\bar{x}_{obs}$ e $\mu_0$:

\begin{align*}
\alpha^* &= 2 \times P(\bar{X} < \bar{x}_{obs} \, | \, H_0 \text{
verdadeira}) \quad \text{se }  \bar{x}_{obs} < \mu_0 \\
\alpha^* &= 2 \times P(\bar{X} > \bar{x}_{obs} \, | \, H_0 \text{
verdadeira}) \quad \text{se }  \bar{x}_{obs} > \mu_0 \\
\end{align*}

Como estamos calculando a probabilidade para apenas uma das caudas,
então esse valor é multiplicado por 2.

# Teste de hipótese para a média

## Variância conhecida

Quando a variância populacional é conhecida, a distribuição amostral da
média é $\bar{X} \sim \text{N}(\mu, \sigma^2 / n)$ e a estatística de
teste é

$$
z = \frac{\bar{x} - \mu_0}{\sigma/\sqrt{n}} \sim \text{N}(0,1)
$$

Suponha que uma amostra de $n=30$ valores foram obtidos de uma VA $X
\sim \text{N}(10, 1)$ e deseja-se testar as hipóteses

$$
\begin{align*}
H_0 &: \mu = 10 \\
H_a &: \mu \neq 10
\end{align*}
$$

com $\alpha=0.05$.

```{r}
## Simula X ~ N(10, 1)
set.seed(2019-10-29)
n <- 30
x <- rnorm(n, 10, 1)
(med <- mean(x))
(s2 <- var(x))

## Teste padrão para
## H0: mu = 10
## Ha: mu != 10
mu0 <- 10
## Estatistica de teste
(zcalc <- (med - mu0)/sqrt(1/n))
## Valor critico
(zcrit <- qnorm(.025, mean = 0, sd = 1))
## p-valor
2 * pnorm(zcalc, mean = 0, sd = 1, lower.tail = FALSE)

## Direto, com base na distribuição amostral
2 * pnorm(med, mean = 10, sd = 1/sqrt(n), lower.tail = FALSE)

## Usando simulacao de Monte Carlo
N <- 1e4
## Simulando direto da distribuicao amostral, sob H0
am <- rnorm(N, mean = mu0, sd = 1/sqrt(n))
## Simula da populacao e calcula as medias, sob H0
am2 <- replicate(N, mean(rnorm(n, mu0, 1)))
## Visualização
par(mfrow = c(1, 2))
hist(am, main = "Distribuição amostral")
abline(v = med, col = 2)
hist(am2, main = "Média de amostras")
abline(v = med, col = 2)
par(mfrow = c(1, 1))
## p-valor empírico
2 * sum(am >= med)/N
2 * sum(am2 >= med)/N

## Padroniza a distribuição para N(0,1)
zpad <- (am - mu0)/sqrt(1/n)
hist(zpad)
abline(v = zcalc, col = 2)
## p-valor empírico
2 * sum(zpad >= zcalc)/N
```

## Variância desconhecida

Quando a variância populacional é **desconhecida**, a distribuição
amostral da média é $\bar{X} \sim \text{N}(\mu, s^2 / n)$ e a
estatística de teste é

$$
t = \frac{\bar{x} - \mu_0}{s/\sqrt{n}} \sim t_{(n-1)}
$$

Suponha que uma amostra de $n=30$ valores foram obtidos de uma VA $X
\sim \text{N}(10, 1)$. Na prática não saberemos o verdadeiro valor de
$\sigma^2$, por isso usaremos a variância amostral $s^2$ no lugar de
$\sigma^2$. Assim, deseja-se testar as hipóteses

$$
\begin{align*}
H_0 &: \mu = 10 \\
H_a &: \mu \neq 10
\end{align*}
$$

com $\alpha=0.05$.

```{r}
## Simula de N(10, 1), mas agora asumindo que a variância é desconhecida
set.seed(2019-10-29)
n <- 30
x <- rnorm(n, 10, 1)
(med <- mean(x))
(s2 <- var(x))

## Teste padrão para
## H0: mu = 10
## Ha: mu != 10
mu0 <- 10
t.test(x = x, alternative = "two.sided", mu = mu0)
## Estatística de teste
(tcalc <- (med - mu0)/sqrt(s2/n))
## Valor crítico
(tcrit <- qt(.025, df = n - 1))
## p-valor
2 * pt(tcalc, df = n - 1, lower.tail = FALSE)

## Teste por simulação de Monte Carlo
N <- 1e4
## Simula direto da distribuição amostral da média
am <- rnorm(N, mean = mu0, sd = sqrt(s2/n))
## Calcula média de amostras de tamanho n da população, com a variância
## estimada a partir dos dados
am2 <- replicate(N, mean(rnorm(n, mu0, sqrt(s2))))
## Visualização
par(mfrow = c(1, 2))
hist(am, main = "Distribuição amostral")
abline(v = med, col = 2)
hist(am2, main = "Média de amostras")
abline(v = med, col = 2)
par(mfrow = c(1, 1))
## p-valor empírico
2 * sum(am >= med)/N
2 * sum(am2 >= med)/N

## Padroniza a distribuição para t(n - 1)
tpad <- (am - mu0)/sqrt(s2/n)
hist(tpad)
abline(v = tcalc, col = 2)
## p-valor empírico
2 * sum(tpad >= tcalc)/N
```

## Comparação de duas médias (variâncias iguais)

Considere duas populações $X_1$ e $X_2$ com médias $\mu_1$ e $\mu_2$,
e desvios-padrão $\sigma_1$ e $\sigma_2$, ou seja
$$
X_1 \sim \text{N}(\mu_1, \sigma_1^2)
\qquad\text{e}\qquad
X_2 \sim \text{N}(\mu_2, \sigma_2^2).
$$

A "**nova**" variável $\overline{X}_d = (\overline{X}_1 -
\overline{X}_2)$ também possui distribuição normal com

$$
\begin{aligned}
\text{E}(\overline{X}_1 - \overline{X}_2) &= \mu_1 - \mu_2 \\
\text{V}(\overline{X}_1 - \overline{X}_2) &=
  \text{V}(\overline{X}_1) + \text{V}(\overline{X}_2) \\
  &= \frac{\sigma^2_1}{n_1} + \frac{\sigma^2_2}{n_2},
\end{aligned}
$$

ou seja, a **distribuição amostral da diferença de médias é**

$$
\overline{X}_d = (\overline{X}_1 - \overline{X}_2) \sim
  \text{N}\left(\mu_1 - \mu_2,
  \frac{\sigma^2_1}{n_1} + \frac{\sigma^2_2}{n_2}\right).
$$

Quando a variância populacional é **desconhecida**, utilizamos $s^2$
como estimativa para $\sigma^2$, e pode-se considerar dois casos
distintos

- **Variâncias iguais:** quando é razoável supor que as variâncias
  populacionais são iguais, ou seja $\sigma_1^2 = \sigma_2^2$. Nesse caso
  a distribuição amostral da diferença média é
  $$
  \overline{X}_d = (\overline{X}_1 - \overline{X}_2) \sim
  \text{N}\left(\mu_1 - \mu_2,
  \frac{s^2}{n_1} + \frac{s^2}{n_2}\right)
  $$
  onde $s^2$ é média ponderada das variâncias amostrais
  $$
  s^2 = \frac{(n_1 - 1) \cdot s_1^2 + (n_2 - 1)
    \cdot s_2^2}{n_1 + n_2 - 2}
  $$
- **Variâncias diferentes:** quando não se pode fazer nenhuma suposição
  sobre a igualdade das variâncias populacionais, ou seja $\sigma_1^2
  \neq \sigma_2^2$. Nesse caso a distribuição amostral da diferença
  média é
  $$
  \overline{X}_d = (\overline{X}_1 - \overline{X}_2) \sim
  \text{N}\left(\mu_1 - \mu_2,
  \frac{s^2_1}{n_1} + \frac{s^2_2}{n_2}\right)
  $$
  onde $s^2_1$ e $s^2_2$ são as variâncias de cada amostra (na
  estatística de teste os graus de liberdade precisam ser ajustados
  corretamente).

### Exemplo (chacais)

O exemplo abaixo é uma adaptação de um exemplo clássico analisado por
Manly (1997). Os dados se referem ao comprimento das mandíbulas de 20
exemplares de chacais (10 de cada sexo) disponíveis no Museu de História
Natural Britânico.

Considere que $\mu_1$ seja a média populacional dos comprimentos das
mandíbulas de chacaias machos, e que $\mu_2$ se refere às fêmeas. Os
pesquisadores supõem que as mandíbulas dos machos são, em média, maiores
que as das fêmeas. Dessa forma um teste de hipótese pode ser formulado
com as seguintes hipóteses

$$
\begin{align*}
H_0 &: \mu_1 - \mu_2 = 0 \Rightarrow \mu_1 = \mu_2 \\
H_a &: \mu_1 - \mu_2 > 0 \Rightarrow \mu_1 > \mu_2
\end{align*}
$$

As variâncias populacionais são desconhecidas, mas assume-se que sejam
iguais, portanto a estatística de teste é

$$
t = \frac{(\overline{x}_1 - \overline{x}_2) - (\mu_1 - \mu_2)}{
  \displaystyle\sqrt{\frac{s^2}{n_1} +
  \displaystyle\frac{s^2}{n_2}}} =
\frac{\overline{x}_1 - \overline{x}_2}{
  \displaystyle\sqrt{\frac{s^2}{n_1} +
  \displaystyle\frac{s^2}{n_2}}} \sim t_\nu,
$$

onde

$$
s^2 = \frac{(n_1 - 1) \cdot s_1^2 + (n_2 - 1) \cdot s_2^2}
  {n_1 + n_2 - 2}
$$
e
$$
\nu = n_1 + n_2 - 2
$$
são os graus de liberdade.

```{r}
## Exemplo adaptado de Manly (1997)
## Comparação do comprimento da mandíbula de chacais machos e fêmeas
set.seed(2)
machos <- c(120, 107, 110, 116, 114, 111, 113, 117, 114, 112)
## Simula diferença para as femeas
femeas <- rnorm(10, mean(machos) - 2, sd = sd(machos))
da <- data.frame(comp = c(machos, femeas),
                 sexo = c(rep("M", 10), rep("F", 10)))
densityplot(~comp, groups = sexo, data = da, auto.key = TRUE)
## Média por sexo
tapply(da$comp, da$sexo, mean)
## Diferença das médias
diff(tapply(da$comp, da$sexo, mean))
```

#### Procedimento padrão {-}

```{r}
## Teste F para igualdade de variâncias
var.test(x = machos, y = femeas)

## Média de cada sexo
(m1 <- mean(machos))
(m2 <- mean(femeas))
## Diferença entre as médias amostrais
(med.amostral <- m1 - m2)
## Calcula o desvio padrão ponderado
n1 <- length(machos)
v1 <- var(machos)
n2 <- length(femeas)
v2 <- var(femeas)
(s.pond <- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2)/(n1 + n2 - 2)))

## Teste de hipótese para
## H0: mu1 = mu2
## Ha: mu1 > mu2
mu0 <- 0
t.test(x = machos, y = femeas, alternative = "greater",
       var.equal = TRUE, mu = mu0)
## Estatística de teste
(tcalc <- (m1 - m2)/(s.pond * sqrt(1/n1 + 1/n2)))
## Valor crítico
(tcrit <- qt(.025, df = n1 + n2 - 2, lower.tail = FALSE))
## p-valor
pt(tcalc, df = n1 + n2 - 2, lower.tail = FALSE)
```

#### Usando simulação de Monte Carlo {-}

```{r}
## Teste por simulação de Monte Carlo
N <- 1e4
## Simula direto da distribuição amostral
am <- replicate(N, rnorm(1, mu0, s.pond * sqrt(1/n1 + 1/n2)))
```

Para simular direto dos dados, partimos da hipótese nula de que as duas
médias são iguais, e as variâncias são as mesmas. Nesse caso, podemos
simular assumindo que a média é igual à média dos machos, e da mesma
forma, podemos assumir que a média da população é igual a média das
fêmeas.

```{r}
## Usando media dos machos: obtém a diferença das médias entre machos e
## fêmeas, assumindo que a média na população é igual a média dos machos
am.machos <- replicate(
    N, diff(tapply(rnorm(20, m1, s.pond), da$sexo, mean))
)
## Usando media das femeas: obtém a diferença das médias entre machos e
## fêmeas, assumindo que a média na população é igual a média dos fêmeas
am.femeas <- replicate(
    N, diff(tapply(rnorm(20, m2, s.pond), da$sexo, mean))
)

## Visualização
par(mfrow = c(1, 3))
hist(am, main = "Distribuição amostral")
abline(v = med.amostral, col = 2)
hist(am.machos, main = "Média de amostras (machos)")
abline(v = med.amostral, col = 2)
hist(am.femeas, main = "Média de amostras (fêmeas)")
abline(v = med.amostral, col = 2)
par(mfrow = c(1, 1))
## p-valor empírico
sum(am >= med.amostral)/N
sum(am.machos >= med.amostral)/N
sum(am.femeas >= med.amostral)/N

## Padroniza a distribuição para t(n1 + n2 - 2)
tpad <- (am - mu0)/(s.pond * sqrt(1/n1 + 1/n2))
hist(tpad)
abline(v = tcalc, col = 2)
## p-valor
sum(tpad >= tcalc)/N
```

#### Quando o método pode não ser muito bom {-}

Aqui usamos os dados originais do Manly (1997).

```{r, cache=TRUE}
## Exemplo original do Manly (1997)
machos <- c(120, 107, 110, 116, 114, 111, 113, 117, 114, 112)
femeas <- c(110, 111, 107, 108, 110, 105, 107, 106, 111, 111)
da <- data.frame(comp = c(machos, femeas),
                 sexo = c(rep("M", 10), rep("F", 10)))
densityplot(~comp, groups = sexo, data = da, auto.key = TRUE)
## Média por sexo
tapply(da$comp, da$sexo, mean)
## Diferença das médias
diff(tapply(da$comp, da$sexo, mean))

## Média de cada sexo
(m1 <- mean(machos))
(m2 <- mean(femeas))
## Diferença entre as médias amostrais
(med.amostral <- m1 - m2)
## Calcula o desvio padrão ponderado
n1 <- length(machos)
v1 <- var(machos)
n2 <- length(femeas)
v2 <- var(femeas)
(s.pond <- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2)/(n1 + n2 - 2)))

## Teste F para igualdade de variâncias
var.test(x = machos, y = femeas)

## Teste de hipótese para
## H0: mu1 = mu2
## Ha: mu1 > mu2
mu0 <- 0
t.test(x = machos, y = femeas, alternative = "greater",
       var.equal = TRUE, mu = mu0)
## Estatística de teste
(tcalc <- (m1 - m2)/(s.pond * sqrt(1/n1 + 1/n2)))
## Valor crítico
(tcrit <- qt(.025, df = n1 + n2 - 2, lower.tail = FALSE))
## p-valor
pt(tcalc, df = n1 + n2 - 2, lower.tail = FALSE)

## Teste por simulação de Monte Carlo
N <- 1e5 # NOTE o aumento no número de simulações
## Simula direto da distribuição amostral
library(future.apply) # para um replicate mais eficiente (em paralelo)
plan(multicore, workers = 4)
am <- future_replicate(N, rnorm(1, mu0, s.pond * sqrt(1/n1 + 1/n2)))
## Usando media dos machos
am.machos <- future_replicate(
    N, diff(tapply(rnorm(20, m1, s.pond), da$sexo, mean))
)
## Usando media das femeas
am.femeas <- future_replicate(
    N, diff(tapply(rnorm(20, m2, s.pond), da$sexo, mean))
)

## Visualização
par(mfrow = c(1, 3))
hist(am, main = "Distribuição amostral")
abline(v = med.amostral, col = 2)
hist(am.machos, main = "Média de amostras (machos)")
abline(v = med.amostral, col = 2)
hist(am.femeas, main = "Média de amostras (fêmeas)")
abline(v = med.amostral, col = 2)
par(mfrow = c(1, 1))

## p-valor empírico
format(sum(am >= med.amostral)/N, digits = 10, scientific = FALSE)
format(sum(am.machos >= med.amostral)/N, digits = 10, scientific = FALSE)
format(sum(am.femeas >= med.amostral)/N, digits = 10, scientific = FALSE)

## Padroniza a distribuição para t(n1 + n2 - 2)
tpad <- (am - mu0)/(s.pond * sqrt(1/n1 + 1/n2))
hist(tpad)
abline(v = tcalc, col = 2)
## p-valor
sum(tpad >= tcalc)/N
```

Isso mostra que a simulação pode não conseguir representar casos
extremos, embora a conclusão não seria alterada.

# Teste de hipótese para uma proporção

Se $Y \sim \text{Ber}(p)$, então a proporção amostral
$$
  \hat{p} = \frac{1}{n} \sum_{i=1}^{n} y_i
$$
é a **melhor estimativa** para a proporção populacional $p$.

Já vimos que, quando ambas condições são satisfeitas,

- $np \geq 5$
- $n(1 - p) \geq 5$,

a distribuição amostral de $\hat{p}$ pode ser aproximada (pelo TLC) por
$$
  \hat{p} \overset{\text{aprox}}{\sim}
  \text{N}\left(p, \frac{p(1 - p)}{n} \right).
$$

Podemos usar a distribuição Normal como aproximação da Binomial e,
portanto, usamos a **estatística de teste**
$$
  z = \frac{\hat{p} - p_0}{\sqrt{\frac{p_0 (1 - p_0)}{n}}}
  \sim \text{N}(0, 1)
$$
em que $p_0$ é o valor de proporção de teste na hipótese nula.

## Exemplo

Suponha que em uma amostra de $n=250$ itens, 32 apresentaram algum tipo
de defeito. Deseja-se testas as hipóteses

$$
\begin{align*}
H_0 &: p = 0.15\\
H_a &: p < 0.15
\end{align*}
$$

```{r}
## Dados: y = 32 sucessos em n = 250 tentativas
n <- 250
y <- 32

## Proporção amostral
(theta.hat <- y/n)

## Teste de hipótese
## H0: theta = 0.15
## Ha: theta < 0.15
theta0 <- 0.15
## A aproximação pela normal funciona bem quando
## np >= 5 e n(1-p) >=5
n * theta.hat
n * (1 - theta.hat)
## Estatistica de teste (aproximação pela normal)
(zcalc <- (theta.hat - theta0)/sqrt((theta0 * (1 - theta0))/n))
## Com alpha = 0.05, o valor cítico é
(zcrit <- qnorm(.05))
## p-valor
pnorm(zcalc)
pbinom(y, size = n, prob = theta0) # teste exato
binom.test(x = 32, n = 250, p = 0.15, alternative = "less")
## Aproximação (com correção de continuidade)
prop.test(x = 32, n = 250, p = 0.15, alternative = "less")
## Aproximação (SEM correção de continuidade): similar à aproximação
## pela Normal
prop.test(x = 32, n = 250, p = 0.15, alternative = "less",
          correct = FALSE)

## Teste por simulação de Monte Carlo
N <- 1e4
## Simula direto da distribuição amostral da proporção (aproximada pela
## normal)
am <- rnorm(N, mean = theta0, sd = sqrt((theta0 * (1 - theta0))/n))
## Simula direto da população, sob theta0
am2 <- rbinom(N, size = n, prob = theta0)
## Calcula a proporção amostral
am2 <- am2/n

## Visualização
par(mfrow = c(1, 2))
hist(am, main = "Distribuição amostral", freq = FALSE)
## Aproximação pela normal
curve(dnorm(x, theta0, sqrt((theta0 * (1 - theta0))/n)),
      from = 0, to = .3, add = TRUE, col = 2)
abline(v = theta.hat, col = 2)
hist(am2, main = "Proporções de amostras", freq = FALSE)
## Aproximação pela normal
curve(dnorm(x, theta0, sqrt((theta0 * (1 - theta0))/n)),
      from = 0, to = .3, add = TRUE, col = 2)
abline(v = theta.hat, col = 2)
par(mfrow = c(1, 1))

## p-valor empírico
sum(am <= theta.hat)/N
sum(am2 <= theta.hat)/N # mais próximo ao teste exato

## Padroniza a distribuição para N(0,1)
zpad <- (am - theta0)/sqrt((theta0 * (1 - theta0))/n)
hist(zpad, freq = FALSE)
curve(dnorm, -3, 3, add = TRUE, col = 2)
abline(v = zcalc, col = 2)
## p-valor empírico
sum(zpad <= zcalc)/N
```

<!--
## Exemplo (moedas)

Suponha que uma pessoa lançou uma moeda 70 vezes e marcou 1 quando caiu
cara e 0 quando saiu coroa. Esse foi o resultado obtido

```{r}
x <- c(1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0,
       0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1,
       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,
       0, 1, 0, 1, 1, 0, 0, 0)
## Proporção amostral
sum(x)/length(x)
```

Mas não estamos interessados em saber a proporção de caras e coroas, mas
sim quantas vezes a face da moeda mudou durante o experimento.

```{r}
## Número de trocas de face
(o <- sum(abs(diff(x))))
```

Podemos então simular desse experimento

```{r}
## Função que lança uma moeda verdadeira e retorna o número de
## trocas. Ela reproduz o experimento sob a hipótese nula, ou seja, com
## p=0.5 e lançamentos independentes (sem memória).
moeda <- function(n){
    sum(abs(diff(sample(0:1, n, replace=TRUE))))
}
moeda(70)

## Faz várias execuções do experimento aleatório.
r <- replicate(100000, moeda(70))

## A distribuição amostral da estatística número de trocas.
hist(r, breaks=seq(min(r), max(r)+1, by=1)-0.5, prob=TRUE,
     xlab="Número de trocas em 70 lançamentos",
     ylab="Densidade", main=NULL)
abline(v=o, col=2)
text(x=o, y=par()$usr[4], label="Estatística observada", srt=90,
     adj=c(1.25,-0.25))

plot(ecdf(r))
abline(v=o, col=2)
text(x=o, y=par()$usr[4], label="Estatística observada", srt=90,
     adj=c(1.25,-0.25))

## Como a v.a. é discreta.
sum(r<=o)/length(r)
sum(r<o)/length(r)

pbinom(o, 70, prob = 0.5)
prop.test(x = 27, n = 70, alternative = "less")
binom.test(x = 27, n = 70, alternative = "less")

2 * sum(r<=o)/length(r)
2 * sum(r<o)/length(r)
prop.test(x = 27, n = 70, alternative = "two.sided")
binom.test(x = 27, n = 70, alternative = "two.sided")

## A distribuição do número de trocas sob H0 é uma Binomial.
i <- 0:69
p <- pbinom(i, size=69, p=0.5)

plot(ecdf(r), verticals=TRUE, cex=NA, main=NULL,
     xlab="Número de trocas em 70 lançamentos",
     ylab="Probabilidade acumulada")
lines(p~i, type="s", col=2)
legend("right",
       legend=c("Distribuição empírica", "Distribuição teórica"),
       col=1:2, lty=1, bty="n")
```
-->

```{r, include=FALSE, eval=FALSE}
##----------------------------------------------------------------------
## Exemplo do Walmes
set.seed(4)
da <- data.frame(local=gl(2, 30, labels=c("N","S")))
da$bico <- with(da, rnorm(length(local),
                          mean=49+2*as.integer(local),
                          sd=2))

densityplot(~bico, groups = local, data = da, auto.key = TRUE)
tapply(da$bico, da$local, mean)
diff(tapply(da$bico, da$local, mean))

(m1 <- mean(da$bico[da$local == "N"]))
(m2 <- mean(da$bico[da$local == "S"]))


(med.amostral <- m1 - m2)

n1 <- length(da$bico[da$local == "N"])
v1 <- var(da$bico[da$local == "N"])
n2 <- length(da$bico[da$local == "S"])
v2 <- var(da$bico[da$local == "S"])
(s.pond <- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2)/(n1 + n2 - 2)))


t.test(bico ~ local, data = da, alternative = "less",
       var.equal = TRUE)

mu0 <- 0

(tcalc <- (m1 - m2)/(s.pond * sqrt(1/n1 + 1/n2)))
(tcrit <- qt(.025, df = n1 + n2 - 2, lower.tail = TRUE))
pt(tcalc, df = n1 + n2 - 2, lower.tail = TRUE)

N <- 10000
am <- replicate(N, rnorm(1, 0, s.pond * sqrt(1/n1 + 1/n2)))
## Usando media dos machos
am <- replicate(N, diff(tapply(rnorm(60, m1, s.pond), da$local, mean)))
## Usando media das femeas
am <- replicate(N, diff(tapply(rnorm(60, m2, s.pond), da$local, mean)))

hist(am)
abline(v = med.amostral, col = 2)

sum(am <= med.amostral)/N
sum(am < med.amostral)/N

## Padroniza a distribuição das propoções amostrais
tt <- (am - mu0)/(s.pond * sqrt(1/n1 + 1/n2))
hist(tt, freq = FALSE)
abline(v = tcalc, col = 2)

## Proporcao da amostra abaixo de theta0 ~ "p-valor"
sum(tt <= tcalc)/N
```

# Cálculo da taxa empírica do erro do tipo I

```{r}
## Obtém o valor da estatística t do teste de Student para a média de
## uma população. Assume que a distribuição de X seja normal.
simula0 <- function(n, mu0, sig0){
    X <- rnorm(n, mean=mu0, sd=sig0)
    T <- (mean(X)-mu0)/(sqrt(var(X)/n))
    return(T)
}

simula0(n=10, mu0=0, sig0=1)

t <- replicate(10000, simula0(n=10, mu0=0, sig0=1))

## Comparação por distribuições acumuladas.
par(mfrow = c(1, 2))
plot(ecdf(t), xlim=c(-5, 5))
curve(pt(x, df=10-1), add=TRUE, col=2)
curve(pnorm(x), add=TRUE, col=3)
## Comparação pela densidade.
plot(density(t), xlim=c(-5, 5))
curve(dt(x, df=10-1), add=TRUE, col=2)
curve(dnorm(x), add=TRUE, col=3)
par(mfrow = c(1, 1))

## p-valor da simulação.
sum(abs(t) >= qt(0.975, df=10-1))/length(t)
sum(abs(t) >= qt(0.95, df=10-1))/length(t)

## Distribuição da estatística com afastamento dos pressupostos sobre a
## distribuição da população (X) que não tem distribuição normal.
simula1 <- function(n, mu0=1){
    X <- rexp(n, 1)
    T <- (mean(X)-mu0)/(sqrt(var(X)/n))
    return(T)
}

## Tamanho da amostra da exponencial
n <- 5
t <- replicate(10000, simula1(n=n))

plot(ecdf(t), xlim=c(-5, 5))
curve(pt(x, df=n-1), add=TRUE, col=2)
curve(pnorm(x), add=TRUE, col=3)

## p-valor real vs nível se significância nominal.
sum(abs(t) >= qt(0.975, df=n-1))/length(t)
sum(abs(t) >= qt(0.95, df=n-1))/length(t)

## O que aconteceria se o tamanho da amostra da exponanecial fosse
## maior?
n <- 50
t <- replicate(10000, simula1(n=n))

plot(ecdf(t), xlim=c(-5, 5))
curve(pt(x, df=n-1), add=TRUE, col=2)
curve(pnorm(x), add=TRUE, col=3)

## p-valor real vs nível se significância nominal.
sum(abs(t) >= qt(0.975, df=n-1))/length(t)
sum(abs(t) >= qt(0.95, df=n-1))/length(t)
```
