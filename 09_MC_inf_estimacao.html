<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />


<meta name="author" content="Fernando P. Mayer" />


<title>Métodos de Monte Carlo em inferência estatística</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.11.4/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/textmate.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/font-awesome-5.1.0/css/all.css" rel="stylesheet" />
<link href="site_libs/font-awesome-5.1.0/css/v4-shims.css" rel="stylesheet" />
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-66454501-13"></script>
<script>
 window.dataLayer = window.dataLayer || [];
 function gtag(){dataLayer.push(arguments);}
 gtag('js', new Date());

 gtag('config', 'UA-66454501-13');
</script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>





<link rel="stylesheet" href="default" type="text/css" />
<link rel="stylesheet" href="config/sydney-site.css" type="text/css" />
<link rel="stylesheet" href="config/sydney-site-fonts.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.tab('show');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}

.tocify-subheader {
  display: inline;
}
.tocify-subheader .tocify-item {
  font-size: 0.95em;
}

</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">CE089</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="aulas.html">Aulas</a>
</li>
<li>
  <a href="referencias.html">Referências</a>
</li>
<li>
  <a href="materiais.html">Materiais</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/leg-ufpr/ce089">
    <span class="fas fa-github fa-lg"></span>
     
    GitHub
  </a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Métodos de Monte Carlo em inferência estatística</h1>
<h3 class="subtitle">Estimadores e propriedades de estimadores</h3>
<h4 class="author">Fernando P. Mayer</h4>

</div>


<div id="introdução" class="section level1">
<h1><span class="header-section-number">1</span> Introdução</h1>
<ul>
<li>Métodos de Monte Carlo representam uma série de ferramentas computacionais na estatística moderna.</li>
<li>Os métodos de Monte Carlo podem se referir à qualquer método em inferência estatística ou análise numérica onde algum método de simulação é utilizado.</li>
<li>Os métodos de Monte Carlo podem ser usados para:
<ul>
<li>Estimar parâmetros através da distribuição amostral de uma estatística</li>
<li>Calcular o erro quadrático médio (EQM) de uma estimativa</li>
<li>Estimar o nível de cobertura de intervalos de confiança</li>
<li>Encontrar a taxa empírica do erro tipo I em um teste de hipótese</li>
<li>Estimar o poder de um teste de hipótese</li>
<li>Comparar a performance de diferentes procedimentos aplicados a um mesmo problema</li>
</ul></li>
<li>Na inferência estatística, sabemos que sempre existe incerteza associada a qualquer estimativa</li>
<li>Para investigar a incerteza, o método apresentado aqui, também chamado de <strong>bootstrap paramétrico</strong>, utiliza repetidas amostragens de um modelo probabilístico</li>
<li>Se podemos simular o processo estocástico que gerou os dados, através da geração de diferentes amostras sob as mesmas condições, esperamos ao final ter uma réplica aproximada do processo em si, refletido nas amostras</li>
</ul>
</div>
<div id="inferência-estatística" class="section level1">
<h1><span class="header-section-number">2</span> Inferência estatística</h1>
<p>Seja <span class="math inline">\(X\)</span> uma variável aleatória com função densidade (ou de probabilidade) denotada por <span class="math inline">\(f(x,\theta)\)</span>, em que <span class="math inline">\(\theta\)</span> é um parâmetro desconhecido. Chamamos de <strong>inferência estatística</strong> o problema que consiste em especificar um ou mais valores para <span class="math inline">\(\theta\)</span>, baseado em um conjunto de valores <span class="math inline">\(X\)</span>.</p>
<p>A inferência pode ser feita de duas formas:</p>
<ul>
<li>estimativa pontual</li>
<li>estimativa intervalar</li>
</ul>
<p><strong>Redução de dados</strong></p>
<ul>
<li>Um experimentador usa as informações em uma amostra aleatória <span class="math inline">\(X_1, \ldots, X_n\)</span> para se fazer inferências sobre <span class="math inline">\(\theta\)</span>.</li>
<li>Normalmente <span class="math inline">\(n\)</span> é grande e fica inviável tirar conclusões baseadas em uma longa <strong>lista</strong> de números.</li>
<li>Por isso, um dos objetivos da inferência estatística é <strong>resumir</strong> as informações de uma amostra, da maneira mais <strong>compacta</strong> possível, mas que ao mesmo tempo seja também <strong>informativa</strong>.</li>
<li>Normalmente esse resumo é feito por meio de <strong>estatísticas</strong>, por exemplo, a média amostral e a variância amostral.</li>
</ul>
<p><strong>População e amostra</strong></p>
<ul>
<li>O conjunto de valores de uma característica associada a uma coleção de indivíduos ou objetos de interesse é dito ser uma população.</li>
<li>Uma sequência <span class="math inline">\(X_1, \ldots, X_n\)</span> de <span class="math inline">\(n\)</span> variáveis aleatórias independentes e identicamente distribuídas (iid) com função densidade (ou de probabilidade) <span class="math inline">\(f(x,\theta)\)</span> é dita ser uma amostra aleatória de tamanho <span class="math inline">\(n\)</span> da distribuição de <span class="math inline">\(X\)</span>.</li>
<li>Como normalmente <span class="math inline">\(n&gt;1\)</span>, então temos que a fdp ou fp conjunta será <span class="math display">\[
f(\boldsymbol{x, \theta}) = f(x_1, \ldots, x_n, \theta) = \prod_{i=1}^n
f(x_i, \theta).
\]</span></li>
</ul>
</div>
<div id="estimadores" class="section level1">
<h1><span class="header-section-number">3</span> Estimadores</h1>
<p><strong>Espaço paramétrico</strong></p>
<ul>
<li>O conjunto <span class="math inline">\(\Theta\)</span> em que <span class="math inline">\(\theta\)</span> pode assumir seus valores é chamado de <strong>espaço paramétrico</strong></li>
</ul>
<p><strong>Estimador</strong></p>
<ul>
<li><p>Qualquer estatística que assume valores em <span class="math inline">\(\Theta\)</span> é um estimador para <span class="math inline">\(\theta\)</span>.</p></li>
<li><p>Dessa forma, um <strong>estimador pontual</strong> para <span class="math inline">\(\theta\)</span> é qualquer estatística que possa ser usada para estimar esse parâmetro, ou seja, <span class="math display">\[\hat{\theta} = T(\mathbf{X})\]</span></p></li>
<li><p>Observações:</p>
<ol style="list-style-type: decimal">
<li>Todo estimador é uma estatística, mas nem toda estatística é um estimador.</li>
<li>O valor assumido pelo estimador pontual é chamado de <strong>estimativa pontual</strong>,<span class="math display">\[\hat{\theta} = T(\mathbf{X}) = T(X_1, \ldots, X_n) = t\]</span> ou seja, o estimador é uma <strong>função</strong> da amostra, e a estimativa é o <strong>valor observado</strong> de um estimador (um número) de uma amostra particular.</li>
</ol></li>
</ul>
<p><strong>Estimação pontual</strong></p>
<ul>
<li>A ideia geral por trás da estimação pontual é muito simples:
<ul>
<li>Quando a amostragem é feita a partir de uma população descrita por uma função <span class="math inline">\(f(x,\theta)\)</span>, o conhecimento de <span class="math inline">\(\theta\)</span> a partir da amostra, gera todo o conhecimento para a população.</li>
<li>Dessa forma, é natural que se procure um <strong>método</strong> para se achar um <strong>bom</strong> estimador para <span class="math inline">\(\theta\)</span>.</li>
<li>Existem algumas <strong>propriedades</strong> que definem o que é um bom estimador, ou o “<strong>melhor</strong>” estimador entre uma série de candidatos.</li>
</ul></li>
</ul>
<p><strong>Localização do problema:</strong></p>
<ul>
<li>Considere <span class="math inline">\(X_1, \ldots, X_n\)</span> uma amostra aleatóra de uma variável aleatória <span class="math inline">\(X\)</span> com fdp ou fp <span class="math inline">\(f(x,\theta)\)</span>, <span class="math inline">\(\theta \in \Theta\)</span>. Sejam: <span class="math display">\[
\hat{\theta}_1 = T_1(X_1, ..., X_n) \quad \quad \hat{\theta}_2 =
T_2(X_1, ..., X_n)
\]</span> Qual dos dois estimadores pontuais é <strong>melhor</strong> para <span class="math inline">\(\theta\)</span>?
<ul>
<li>Como não conhecemos <span class="math inline">\(\theta\)</span>, não podemos afirmar que <span class="math inline">\(\hat{\theta}_1\)</span> é melhor do que <span class="math inline">\(\hat{\theta}_2\)</span> e vice-versa.</li>
<li>O problema da estimação pontual é então escolher um estimador <span class="math inline">\(\hat{\theta}\)</span> que se aproxime de <span class="math inline">\(\theta\)</span> segundo algumas <strong>propriedades</strong>.</li>
</ul></li>
</ul>
</div>
<div id="propriedades-dos-estimadores" class="section level1">
<h1><span class="header-section-number">4</span> Propriedades dos estimadores</h1>
<p>De modo geral, um “<strong>bom</strong>” estimador deve ser:</p>
<ol style="list-style-type: decimal">
<li>Não viesado</li>
<li>Consistente</li>
<li>Eficiente</li>
</ol>
<div id="viés" class="section level2">
<h2><span class="header-section-number">4.1</span> Viés</h2>
<div id="erro-quadrático-médio-eqm" class="section level4 unnumbered">
<h4>Erro quadrático médio (EQM)</h4>
<p>O Erro Quadrático Médio (EQM) de um estimador <span class="math inline">\(\hat{\theta}\)</span> de <span class="math inline">\(\theta\)</span> é dado por <span class="math display">\[\begin{align*}
\text{EQM}[\hat{\theta}] &amp;= \text{E}[(\hat{\theta} - \theta)^2] \\
  &amp;= \text{Var}[\hat{\theta}] + \text{B}[\hat{\theta}]^2
\end{align*}\]</span> onde <span class="math display">\[\text{B}[\hat{\theta}] = \text{E}[\hat\theta] - \theta\]</span> é denominado de <strong>viés</strong> ou <strong>vício</strong> do estimador <span class="math inline">\(\hat\theta\)</span>. Portanto, dizemos que um estimador é <strong>não viesado</strong> para <span class="math inline">\(\theta\)</span> quando <span class="math display">\[\text{B}[\hat{\theta}] = 0 \quad \Rightarrow \quad
\text{E}[\hat{\theta}] = \theta\]</span></p>
<p>O EQM é comumente empregado na comparação de estimadores. Podemos dizer que <span class="math inline">\(\hat\theta_1\)</span> é <strong>melhor</strong> do que <span class="math inline">\(\hat\theta_2\)</span> se <span class="math display">\[
\text{EQM}[\hat{\theta}_1] \leq \text{EQM}[\hat{\theta}_2]
\]</span> para todo <span class="math inline">\(\theta\)</span>, com <span class="math inline">\(\leq\)</span> substituído por <span class="math inline">\(&lt;\)</span> pelo menos para um valor de <span class="math inline">\(\theta\)</span>.</p>
<p>Se os estimadores são não viciados, então <span class="math display">\[
\text{Var}[\hat{\theta}_1] \leq \text{Var}[\hat{\theta}_2]
\]</span> Nesse caso, <span class="math inline">\(\hat{\theta}_1\)</span> é dito ser o <strong>Estimador Não Viciado de Variância Uniformemente Mínima</strong> (ENVVUM).</p>
</div>
<div id="estimador-não-viesado" class="section level4 unnumbered">
<h4>Estimador não viesado</h4>
<p>Seja <span class="math inline">\((X_1, \ldots, X_n)\)</span>, uma amostra aleatória de uma variável aleatória com fdp ou fp <span class="math inline">\(f(x,\theta)\)</span>, <span class="math inline">\(\theta \in \Theta\)</span>, dizemos que o estimador <span class="math inline">\(\hat{\theta} = T(\mathbf{X})\)</span> é não viesado para <span class="math inline">\(\theta\)</span> se <span class="math display">\[\text{E}[\hat{\theta}] = \text{E}[T(\mathbf{X})] = \theta \qquad \forall \, \theta
\in \Theta\]</span></p>
<p>Um estimador <span class="math inline">\(\hat\theta\)</span> é dito <strong>assintoticamente não viesado</strong> se <span class="math display">\[\lim_{n \to \infty} \text{E}[\hat{\theta}] = \theta\]</span> Ou seja, para grandes amostras, <span class="math inline">\(\hat\theta\)</span> passa a ser imparcial.</p>
</div>
</div>
<div id="consistência" class="section level2">
<h2><span class="header-section-number">4.2</span> Consistência</h2>
<div id="estimador-consistente" class="section level4 unnumbered">
<h4>Estimador consistente</h4>
<p>Seja <span class="math inline">\((X_1, \ldots, X_n)\)</span>, uma amostra aleatória de uma variável aleatória com fdp ou fp <span class="math inline">\(f(x,\theta)\)</span>, <span class="math inline">\(\theta \in \Theta\)</span>, o estimador <span class="math inline">\(\hat{\theta} = T(\mathbf{X})\)</span> é consistente para <span class="math inline">\(\theta\)</span> se satisfaz simultaneamente <span class="math display">\[\lim_{n \to \infty} \text{E}[\hat{\theta}] = \theta\]</span> e <span class="math display">\[\lim_{n \to \infty} \text{Var}[\hat{\theta}] = 0\]</span></p>
</div>
<div id="exemplo-média-amostral" class="section level4 unnumbered">
<h4>Exemplo (média amostral)</h4>
<p>Média amostral <span class="math inline">\(\bar{x} = \frac{1}{n} \sum_{i=1}^{n} x_i\)</span> como estimador da média populacional <span class="math inline">\(\mu\)</span>: <span class="math display">\[
\text{E}(\bar{x}) = \text{E} \left[ \frac{1}{n} \sum_{i=1}^{n} x_i
\right] = \mu
\]</span></p>
<p><span class="math display">\[
\text{Var}(\bar{x}) = \text{Var} \left[ \frac{1}{n} \sum_{i=1}^{n} x_i
\right] = \frac{\sigma^2}{n}
\]</span> Portanto <span class="math inline">\(\bar{x}\)</span> é um estimador <strong>não viesado</strong> e <strong>consistente</strong> para <span class="math inline">\(\mu\)</span>.</p>
</div>
<div id="exemplo-variância-amostral" class="section level4 unnumbered">
<h4>Exemplo (variância amostral)</h4>
<p>Variância amostral <span class="math inline">\(\hat{\sigma}^2 = \frac{1}{n} \sum_{i=1}^{n} (x_i - \bar{x})^2\)</span> como estimador da variância populacional <span class="math inline">\(\sigma^2\)</span>: <span class="math display">\[
\text{E}(\hat{\sigma}^2) = \text{E} \left[ \frac{1}{n} \sum_{i=1}^{n}
(x_i - \bar{x})^2 \right]
= \left( \frac{n-1}{n} \right) \sigma^2
\]</span> Portanto <span class="math inline">\(\hat{\sigma}^2\)</span> é um estimador <strong>viesado</strong> para <span class="math inline">\(\sigma^2\)</span>. (Embora seja um estimador <strong>assintoticamente</strong> não viesado).</p>
<p>Para eliminar esse vício, podemos definir então um novo estimador: <span class="math inline">\(S^2 = \frac{1}{n-1} \sum_{i=1}^{n} (x_i - \bar{x})^2\)</span>, e <span class="math display">\[
\text{E}(S^2) = \text{E} \left[ \frac{1}{n-1} \sum_{i=1}^{n} (x_i -
\bar{x})^2 \right] = \sigma^2
\]</span> que é então um estimador <strong>não viesado</strong> para <span class="math inline">\(\sigma^2\)</span>.</p>
</div>
</div>
<div id="eficiência" class="section level2">
<h2><span class="header-section-number">4.3</span> Eficiência</h2>
<div id="eficiência-relativa" class="section level4 unnumbered">
<h4>Eficiência relativa</h4>
<p>Sejam <span class="math inline">\(\hat{\theta}_1 = T_1(\mathbf{X})\)</span> e <span class="math inline">\(\hat{\theta}_2 = T_2(\mathbf{X})\)</span> dois estimadores pontuais <strong>não viesados</strong> para <span class="math inline">\(\theta\)</span>. A eficiência relativa de <span class="math inline">\(\hat{\theta}_1\)</span> em relação a <span class="math inline">\(\hat{\theta}_2\)</span> é <span class="math display">\[\text{ER}[\hat{\theta}_1, \hat{\theta}_2] =
\frac{\text{Var}[\hat{\theta}_1]}{\text{Var}[\hat{\theta}_2]}\]</span></p>
<p>Se:</p>
<ul>
<li><span class="math inline">\(\text{ER}[\hat{\theta}_1, \hat{\theta}_2] &gt; 1\)</span> <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\hat\theta_2\)</span> é mais eficiente</li>
<li><span class="math inline">\(\text{ER}[\hat{\theta}_1, \hat{\theta}_2] &lt; 1\)</span> <span class="math inline">\(\Rightarrow\)</span> <span class="math inline">\(\hat\theta_1\)</span> é mais eficiente</li>
</ul>
</div>
<div id="exemplo-média-e-mediana" class="section level4 unnumbered">
<h4>Exemplo (média e mediana)</h4>
<p>Uma amostra <span class="math inline">\((X_1, \ldots, X_n)\)</span> é retirada de uma população com <span class="math inline">\(X \sim \text{N}(\mu, \sigma^2)\)</span>, e dois estimadores são propostos para <span class="math inline">\(\mu\)</span>: <span class="math display">\[
\hat{\mu}_1 = \bar{X} \quad \text{e} \quad \hat{\mu}_2 =
\text{mediana}(X_1, \ldots, X_n)
\]</span> Qual dos dois é melhor para <span class="math inline">\(\mu\)</span>?</p>
<p>Podemos notar que <span class="math display">\[\begin{align*}
\text{E}(\hat{\mu}_1) &amp;= \text{E}(\bar{X}) = \mu \\
\text{Var}(\hat{\mu}_1) &amp;= \text{Var}(\bar{X}) = \sigma^2/n
\end{align*}\]</span> <span class="math display">\[\begin{align*}
\text{E}(\hat{\mu}_2) &amp;= \text{E}(\text{mediana}(X_1, \ldots, X_n)) = \mu \\
\text{Var}(\hat{\mu}_2) &amp;= \text{Var}(\text{mediana}(X_1, \ldots, X_n))
= (\pi/2)(\sigma^2/n)
\end{align*}\]</span> Portanto, ambos são estimadores não viesados e consistentes. Mas: <span class="math display">\[
\text{ER}[\hat{\mu}_1, \hat{\mu}_2] =
\frac{\text{Var}[\hat{\mu}_1]}{\text{Var}[\hat{\mu}_2]} =
\frac{\sigma^2/n}{(\pi/2)(\sigma^2/n)} = \frac{2}{\pi} = 0,63
\]</span> Como <span class="math inline">\(\text{ER}[\hat{\mu}_1, \hat{\mu}_2] &lt; 1\)</span> então <span class="math inline">\(\hat{\mu}_1 = \bar{X}\)</span> é mais <strong>eficiente</strong>.</p>
</div>
</div>
<div id="erro-padrão" class="section level2">
<h2><span class="header-section-number">4.4</span> Erro padrão</h2>
<p>O <strong>erro padrão</strong> de um estimador dá uma ideia da <strong>precisão</strong> da estimativa.</p>
<p>O erro padrão (EP) de um estimador é o seu desvio-padrão (raíz quadrada da variância), ou seja, <span class="math display">\[
\text{EP}(\hat\theta) = \sqrt{\text{Var}(\hat\theta)}
\]</span></p>
<div id="exemplo-erro-padrão-da-média" class="section level4 unnumbered">
<h4>Exemplo (erro padrão da média)</h4>
<p>Sabemos que a distribuição de <span class="math inline">\(\bar{X}\)</span> tem média <span class="math inline">\(\mu\)</span> e variância <span class="math inline">\(\sigma^2/n\)</span>. Então o erro padrão de <span class="math inline">\(\bar{X}\)</span> é <span class="math display">\[
\text{EP}(\bar{X}) = \sqrt{\text{Var}(\bar{X})} =
\sqrt{\frac{\sigma^2}{n}} = \frac{\sigma}{\sqrt{n}}
\]</span></p>
</div>
</div>
</div>
<div id="métodos-de-monte-carlo-para-estimação" class="section level1">
<h1><span class="header-section-number">5</span> Métodos de Monte Carlo para estimação</h1>
<p>Suponha <span class="math inline">\(X_1, \ldots, X_n\)</span> uma amostra aleatória da distribuição de <span class="math inline">\(X\)</span>. Um estimador <span class="math inline">\(\hat\theta\)</span> para um parâmetro <span class="math inline">\(\theta\)</span> é a função <span class="math display">\[
\hat\theta = T(x_1, \ldots, x_n)
\]</span> da amostra. Seja <span class="math inline">\(\mathbf{x} = (x_1, \ldots, x_n)&#39; \in \mathbb{R}^n\)</span>, e vamos denotar por <span class="math inline">\(\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \ldots\)</span>, uma sequência de amostras aleatórias <strong>independentes</strong> geradas a partir da distribuição de <span class="math inline">\(X\)</span>.</p>
<p>Valores aleatórios da <strong>distribuição amostral</strong> de <span class="math inline">\(\hat\theta\)</span> podem ser obtidos através de <span class="math inline">\(N\)</span> repetidas amostras aleatórias independentes <span class="math inline">\(\mathbf{x}^{(j)}\)</span>, e calculando-se <span class="math display">\[
\hat\theta^{(j)} = T(x_1^{(j)}, \ldots, x_n^{(j)}) \quad j = 1, \ldots,
N
\]</span></p>
<p>Dessa forma, se <span class="math inline">\(\hat\theta\)</span> é uma estimativa de <span class="math inline">\(\theta\)</span> da distribuição <span class="math inline">\(f\)</span>, então as <strong>amostras de um bootstrap paramétrico</strong> de <span class="math inline">\(f_{\hat\theta}\)</span> são <span class="math display">\[
f_{\hat\theta} \longrightarrow \mathbf{x}^{(j)} \longrightarrow
\hat\theta^{(j)}
\]</span></p>
<p>A distribuição amostral de <span class="math inline">\(\hat\theta^{(j)}\)</span> deve ser próxima da distribuição amostral verdadeira para <span class="math inline">\(N\)</span> grande. A média da distribuição <span class="math display">\[
\hat\theta_{MC} = \frac{1}{N} \sum_{j=1}^{N} \hat\theta^{(j)}
\]</span> será então uma estimativa pontual para <span class="math inline">\(\theta\)</span>.</p>
<p>Um dos principais objetivos de se usar métodos de Monte Carlo para estimação de algum parâmetro, é o cálculo da <strong>incerteza</strong> associada à estimativa, expressa geralmente pelo <strong>erro padrão</strong>.</p>
<ul>
<li>Em muitos casos, o erro padrão de uma estimativa pode ser obtido diretamente de forma analítica</li>
<li>Em casos mais complexos, a forma analítica pode não existir e mesmo a distribuição amostral pode ser desconhecida</li>
<li>Nesses casos, a distribuição amostral <strong>empírica</strong> construída pelo método de Monte Carlo pode ser utilizada</li>
</ul>
<p>Como a estimativa pontual (de Monte Carlo) para <span class="math inline">\(\theta\)</span> é uma média (<span class="math inline">\(\hat{\theta}_{MC}\)</span>), então seu erro padrão será <span class="math inline">\(\sqrt{\text{Var}(\theta)/N}\)</span> (definição de erro padrão de uma média). Quando a distribuição exata de <span class="math inline">\(\theta\)</span> for desconhecida, podemos substituir a distribuição <span class="math inline">\(F_{\theta}\)</span> pela distribuição empírica <span class="math inline">\(F_N\)</span> da amostra <span class="math inline">\(\hat{\theta}^{(1)}, \ldots, \hat{\theta}^{(N)}\)</span>. Um estimador do tipo <em>plug-in</em> para a variância de <span class="math inline">\(\theta\)</span> será então</p>
<p><span class="math display">\[
\widehat{\text{Var}}(\theta) = \frac{1}{N} \sum_{j=1}^{N} (\theta^{(j)} -
\hat{\theta}_{MC})^2
\]</span></p>
<p>Note que <span class="math inline">\(\widehat{\text{Var}}(\theta)\)</span> é a <strong>variância populacional da pseudo-população finita</strong> <span class="math inline">\(\{\hat{\theta}^{(1)}, \ldots, \hat{\theta}^{(N)}\}\)</span> com distribuição <span class="math inline">\(F_N\)</span>. Com isso, o correspondente estimador para o erro padrão de <span class="math inline">\(\hat{\theta}_{MC}\)</span> é</p>
<p><span class="math display">\[\begin{align*}
\widehat{\text{EP}}_{MC} &amp;= \frac{1}{\sqrt{N}} \sqrt{\frac{1}{N}
  \sum_{j=1}^{N} (\hat\theta^{(j)} - \hat\theta_{MC})^2} \\
  &amp;= \frac{1}{N} \sqrt{\sum_{j=1}^{N} (\hat\theta^{(j)} -
  \hat\theta_{MC})^2}
\end{align*}\]</span></p>
<p>Usando o estimador não viesado para <span class="math inline">\(\text{Var}(\theta)\)</span>, temos</p>
<p><span class="math display">\[
\widehat{\text{EP}}_{MC} = \frac{1}{\sqrt{N}} \sqrt{\frac{1}{N-1}
  \sum_{j=1}^{N} (\hat\theta^{(j)} - \hat\theta_{MC})^2}
\]</span></p>
<p>No entanto, em um experimento de Monte Carlo, o tamanho amostral (<span class="math inline">\(N\)</span>) é grande, de forma que as duas estimativas serão aproximadamente iguais.</p>
<div class="panel panel-primary">
<div class="panel-heading">
Observação: erro padrão no R
</div>
<div class="panel-body">
<p>No R, as funções <code>var()</code> e <code>sd()</code> calculam a variância e o desvio padrão não viesados (com o denominador <span class="math inline">\(n-1\)</span>). Dessa forma, se for utilizar alguma destas funções para calcular o erro-padrão, utilize a última equação mostrada acima.</p>
<p>Por exemplo, se <code>x</code> é um vetor de tamanho <span class="math inline">\(N\)</span> com as estimativas <span class="math inline">\(\hat{\theta}^{(1)}, \ldots, \hat{\theta}^{(N)}\)</span>, então o erro padrão pode ser calculado como</p>
<pre class="r"><code>sd(x)/sqrt(N)</code></pre>
</div>
</div>
</div>
<div id="avaliação-de-estimadores" class="section level1">
<h1><span class="header-section-number">6</span> Avaliação de estimadores</h1>
<div id="exemplo-normal" class="section level2">
<h2><span class="header-section-number">6.1</span> Exemplo (normal)</h2>
<p>Considere uma amostra aleatória (<span class="math inline">\(X_1, \ldots, X_n\)</span>) de uma variável aleatória <span class="math inline">\(X \sim \text{N}(\mu = 3, \sigma^2 = 1)\)</span> e os estimadores pontuais para <span class="math inline">\(\mu\)</span> <span class="math display">\[\hat{\theta}_1 = \frac{1}{n} \sum_{i=1}^n X_i \qquad \text{e} \qquad
\hat{\theta}_2 = \frac{X_{(1)}+X_{(n)}}{2}\]</span> Qual dos dois estimadores pode ser considerado como o <strong>melhor</strong> para estimar o verdadeiro valor de <span class="math inline">\(\mu\)</span>?</p>
<p>Considere os seguintes pseudo-códigos para um estudo de simulação do comportamento destes dois estimadores:</p>
<p><strong>Pseudo-código 1 (viés, precisão e eficiência)</strong></p>
<ol style="list-style-type: decimal">
<li>Simule uma amostra de tamanho <span class="math inline">\(n = 10\)</span> da distribuição considerada</li>
<li>Para essa amostra, calcule a média (<span class="math inline">\(\hat{\theta}_1\)</span>) e o ponto médio (<span class="math inline">\(\hat{\theta}_2\)</span>)</li>
<li>Repita os passos (1) e (2) acima <span class="math inline">\(N = 1000\)</span> vezes</li>
<li>Faça um gráfico da densidade das <span class="math inline">\(N = 1000\)</span> estimativas de <span class="math inline">\(\hat{\theta}_1\)</span> e <span class="math inline">\(\hat{\theta}_2\)</span> e verifique seu comportamento</li>
</ol>
<pre class="r"><code>library(lattice)
library(latticeExtra)
library(plyr)</code></pre>
<pre class="r"><code>## Define valores
N &lt;- 1000
n &lt;- 10
## Gera amostras e calcula estimativas
set.seed(1)
th1 &lt;- replicate(N, mean(rnorm(n, mean = 3, sd = 1)))
th2 &lt;- replicate(N, mean(range(rnorm(n, mean = 3, sd = 1))))
## Converte para data frame
L &lt;- list(th1 = data.frame(est = th1), th2 = data.frame(est = th2))
L &lt;- ldply(L)
str(L)</code></pre>
<pre><code># &#39;data.frame&#39;: 2000 obs. of  2 variables:
#  $ .id: chr  &quot;th1&quot; &quot;th1&quot; &quot;th1&quot; &quot;th1&quot; ...
#  $ est: num  3.13 3.25 2.87 3.12 3.13 ...</code></pre>
<pre class="r"><code>## Distribuição das estimativas
densityplot(
    ~ est | .id, data = L,
    panel = function(x, ...){
        panel.densityplot(x, ...)
        panel.abline(v = mean(x))
    },
    xlab = &quot;Estimativa&quot;, ylab = &quot;Densidade&quot;,
    strip = strip.custom(
        factor.levels = c(expression(hat(theta[1])),
                          expression(hat(theta[2]))))
)</code></pre>
<p><img src="figures/09_MC_inf_estimacao/unnamed-chunk-4-1.png" width="90%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Média das estimativas
tapply(L$est, L$.id, mean)</code></pre>
<pre><code>#      th1      th2 
# 2.993463 3.019900</code></pre>
<pre class="r"><code>## Erro padrão das estimativas
tapply(L$est, L$.id, function(x) sd(x)/sqrt(N))</code></pre>
<pre><code>#        th1        th2 
# 0.01022276 0.01348322</code></pre>
<pre class="r"><code>## Eficiência relativa
var(L$est[L$.id == &quot;th1&quot;])/var(L$est[L$.id == &quot;th2&quot;])</code></pre>
<pre><code># [1] 0.5748422</code></pre>
<p><strong>Pseudo-código 2 (viés e consistência)</strong></p>
<ol style="list-style-type: decimal">
<li>Simule amostras de tamanhos (<span class="math inline">\(n\)</span>) 2, 3, 5, 10, 20, 50, 100, 500, 1000 da distribuição considerada</li>
<li>Para cada amostra de tamanho <span class="math inline">\(n\)</span>, calcule a média (<span class="math inline">\(\hat{\theta}_1\)</span>) e o ponto médio (<span class="math inline">\(\hat{\theta}_2\)</span>)</li>
<li>Repita os passos (1) e (2) acima <span class="math inline">\(N = 100\)</span> vezes</li>
<li>Faça um gráfico das <span class="math inline">\(N = 100\)</span> estimativas de <span class="math inline">\(\hat{\theta}_1\)</span> e <span class="math inline">\(\hat{\theta}_2\)</span> para cada tamanho de amostra <span class="math inline">\(n\)</span> e verifique seu comportamento</li>
</ol>
<pre class="r"><code>## Define valores
N &lt;- 100
nval &lt;- c(2, 3, 5, 10, 20, 50, 100, 500, 1000)
## Calcula média para cada tamanho de amostra
set.seed(1)
th1 &lt;- sapply(
    nval,
    function(n){
        replicate(N, mean(rnorm(n, mean = 3, sd = 1)))
    }
)
str(th1)</code></pre>
<pre><code>#  num [1:100, 1:9] 2.78 3.38 2.75 3.61 3.14 ...</code></pre>
<pre class="r"><code>th1 &lt;- stack(as.data.frame(th1))
levels(th1$ind) &lt;- as.character(nval)
th1$ind &lt;- as.numeric(as.character(th1$ind))
## Calcula ponto médio para cada tamanho de amostra
set.seed(1)
th2 &lt;- sapply(
    nval,
    function(n){
        replicate(N, mean(range(rnorm(n, mean = 3, sd = 1))))
    }
)
str(th2)</code></pre>
<pre><code>#  num [1:100, 1:9] 2.78 3.38 2.75 3.61 3.14 ...</code></pre>
<pre class="r"><code>th2 &lt;- stack(as.data.frame(th2))
levels(th2$ind) &lt;- as.character(nval)
th2$ind &lt;- as.numeric(as.character(th2$ind))
## Converte para data frame
L &lt;- list(th1 = th1, th2 = th2)
L &lt;- ldply(L)
L$.id &lt;- factor(L$.id)
## Distribuição para cada tamanho de amostra
xyplot(
    values ~ ind | factor(.id), L,
    xlab = &quot;Tamanho da amostra (escala log)&quot;, ylab = &quot;Estimativas&quot;,
    strip = strip.custom(
        factor.levels =
            c(expression(hat(theta[1])),
              expression(hat(theta[2])))),
    scales = list(x = list(log = 10))) +
    layer(panel.abline(h = 3))</code></pre>
<p><img src="figures/09_MC_inf_estimacao/unnamed-chunk-6-1.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
<div id="exemplo-uniforme" class="section level2">
<h2><span class="header-section-number">6.2</span> Exemplo (uniforme)</h2>
<p>Considere uma amostra aleatória (<span class="math inline">\(X_1, \ldots, X_n\)</span>) de uma variável aleatória <span class="math inline">\(Y \sim \text{U}(\text{min} = 2, \text{max} = 4)\)</span> (distribuição uniforme no intervalo [2,4]) e os estimadores pontuais para <span class="math inline">\(\mu\)</span> <span class="math display">\[\hat{\theta}_1 = \frac{1}{n} \sum_{i=1}^n X_i \qquad \text{e} \qquad
\hat{\theta}_2 = \frac{X_{(1)}+X_{(n)}}{2}\]</span> Qual dos dois estimadores pode ser considerado como o <strong>melhor</strong> para estimar a média de <span class="math inline">\(Y\)</span>?</p>
<p><strong>Pseudo-código 1 (viés, precisão e eficiência)</strong></p>
<pre class="r"><code>N &lt;- 1000
n &lt;- 10

set.seed(1)
th1 &lt;- replicate(N, mean(runif(n, min = 2, max = 4)))
th2 &lt;- replicate(N, mean(range(runif(n, min = 2, max = 4))))

L &lt;- list(th1 = data.frame(est = th1), th2 = data.frame(est = th2))
L &lt;- ldply(L)
str(L)</code></pre>
<pre><code># &#39;data.frame&#39;: 2000 obs. of  2 variables:
#  $ .id: chr  &quot;th1&quot; &quot;th1&quot; &quot;th1&quot; &quot;th1&quot; ...
#  $ est: num  3.1 3.12 2.84 3.06 3.21 ...</code></pre>
<pre class="r"><code>densityplot(
    ~est | .id, data = L,
    panel = function(x, ...){
        panel.densityplot(x, ...)
        panel.abline(v = mean(x))
    },
    xlab = &quot;Estimativa&quot;, ylab = &quot;Densidade&quot;,
    strip = strip.custom(
        factor.levels =
            c(expression(hat(theta[1])),
              expression(hat(theta[2])))))</code></pre>
<p><img src="figures/09_MC_inf_estimacao/unnamed-chunk-7-1.png" width="90%" style="display: block; margin: auto;" /></p>
<pre class="r"><code>## Média das estimativas
tapply(L$est, L$.id, mean)</code></pre>
<pre><code>#      th1      th2 
# 3.000336 3.002104</code></pre>
<pre class="r"><code>## Erro padrão das estimativas
tapply(L$est, L$.id, sd)</code></pre>
<pre><code>#       th1       th2 
# 0.1902737 0.1205587</code></pre>
<pre class="r"><code>## Eficiência relativa
var(L$est[L$.id == &quot;th1&quot;])/var(L$est[L$.id == &quot;th2&quot;])</code></pre>
<pre><code># [1] 2.490924</code></pre>
<p><strong>Pseudo-código 2 (viés e consistência)</strong></p>
<pre class="r"><code>N &lt;- 100
nval &lt;- c(2, 3, 5, 10, 20, 50, 100, 500, 1000)

set.seed(1)
th1 &lt;- sapply(
    nval,
    function(n){
        replicate(N, mean(runif(n, min = 2, max = 4)))
    }
)
str(th1)</code></pre>
<pre><code>#  num [1:100, 1:9] 2.64 3.48 3.1 3.61 2.69 ...</code></pre>
<pre class="r"><code>th1 &lt;- stack(as.data.frame(th1))
levels(th1$ind) &lt;- as.character(nval)
th1$ind &lt;- as.numeric(as.character(th1$ind))

set.seed(1)
th2 &lt;- sapply(
    nval,
    function(n){
        replicate(N, mean(range(runif(n, min = 2, max = 4))))
    }
)
str(th2)</code></pre>
<pre><code>#  num [1:100, 1:9] 2.64 3.48 3.1 3.61 2.69 ...</code></pre>
<pre class="r"><code>th2 &lt;- stack(as.data.frame(th2))
levels(th2$ind) &lt;- as.character(nval)
th2$ind &lt;- as.numeric(as.character(th2$ind))

L &lt;- list(th1 = th1, th2 = th2)
L &lt;- ldply(L)
L$.id &lt;- factor(L$.id)

xyplot(
    values ~ ind | .id, L,
    xlab = &quot;Tamanho da amostra (escala log)&quot;, ylab = &quot;Estimativas&quot;,
    strip = strip.custom(
        factor.levels =
            c(expression(hat(theta[1])),
              expression(hat(theta[2])))),
    scales = list(x = list(log = 10))) +
    layer(panel.abline(h = 3))</code></pre>
<p><img src="figures/09_MC_inf_estimacao/unnamed-chunk-8-1.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
<div id="exemplo-média-aparada" class="section level2">
<h2><span class="header-section-number">6.3</span> Exemplo (média aparada)</h2>
<p>Considere o problema de se obter uma estimativa de centro de uma distribuição simétrica, sem considerar a média amostral. Podemos pensar em dois estimadores: a <strong>média aparada</strong> e a <strong>mediana</strong>. Qual dos dois estimadores é “melhor” para estimar a média populacional <span class="math inline">\(\mu\)</span>?</p>
<p>Suponha que <span class="math inline">\(X_1, \ldots, X_n\)</span> é uma amsotra aleatória de <span class="math inline">\(X\)</span>, e <span class="math inline">\(X_{(1)}, \ldots, X_{(n)}\)</span> é a correspondente <strong>amostra ordenada</strong>. A média aparada de primeiro nível é calculada retirando-se o menor e o maior valor da amostra. De maneira mais geral, a média aparada de <span class="math inline">\(k\)</span>-ésimo nível pode ser definida como <span class="math display">\[
\overline{X}_{[-k]} = \frac{1}{n-2k} \sum_{i=k+1}^{n-k} X_{(i)}
\]</span></p>
<p>Vamos obter o EQM da média aparada de primeiro nível (<span class="math inline">\(\overline{X}_{[-1]}\)</span>) assumindo que <span class="math inline">\(X \sim \text{N}(0,1)\)</span>. Nesse exemplo, a média da distribuição é zero, e o parâmetro de interesse é <span class="math inline">\(\theta = \text{E}[\overline{X}] = \text{E}[\overline{X}_{[-1]}] = 0\)</span>. Considere que a média aparada de primeiro nível é <span class="math inline">\(T\)</span>. Uma estimativa de <span class="math inline">\(\text{EQM}[T]\)</span> baseado em <span class="math inline">\(N\)</span> replicações é obtida da seguinte forma:</p>
<ol style="list-style-type: decimal">
<li>Gera as repetições <span class="math inline">\(T^{(j)}, j=1, \ldots, N\)</span> repetindo:
<ol style="list-style-type: lower-alpha">
<li>Gere <span class="math inline">\(x_1^{(j)}, \ldots, x_n^{(j)}\)</span> iid da distribuição de <span class="math inline">\(X\)</span></li>
<li>Ordene <span class="math inline">\(x_1^{(j)}, \ldots, x_n^{(j)}\)</span> em ordem crescente, <span class="math inline">\(x_{(1)}^{(j)} \leq \ldots \leq x_{(n)}^{(j)}\)</span></li>
<li>Calcule <span class="math inline">\(T^{(j)} = \frac{1}{n-2} \sum_{i=2}^{n-1} x_{(i)}^{(j)}\)</span></li>
</ol></li>
<li>Calcule <span class="math inline">\(\widehat{\text{EQM}} = \frac{1}{N} \sum_{j=1}^{N} (T^{(j)} - \theta)^2 = \frac{1}{N} \sum_{j=1}^{N} (T^{(j)})^2\)</span></li>
</ol>
<pre class="r"><code>## Tamanho da amostra
n &lt;- 20
## Número de repetições
N &lt;- 1000
tmean1 &lt;- numeric(N)
for (i in 1:N) {
    x &lt;- sort(rnorm(n))
    tmean1[i] &lt;- sum(x[2:(n - 1)])/(n - 2)
}
## Estimativa pontual
(m.tmean1 &lt;- mean(tmean1))</code></pre>
<pre><code># [1] -0.002549744</code></pre>
<pre class="r"><code>## Variância
sum((tmean1 - m.tmean1)^2)/(N - 1)</code></pre>
<pre><code># [1] 0.05046943</code></pre>
<pre class="r"><code>## Erro padrão = desvio padrão da distribuição amostral
sqrt(sum((tmean1 - m.tmean1)^2))/(N - 1)</code></pre>
<pre><code># [1] 0.007107739</code></pre>
<pre class="r"><code>## EQM
(eqm1 &lt;- mean(tmean1^2))</code></pre>
<pre><code># [1] 0.05042546</code></pre>
<pre class="r"><code>hist(tmean1)</code></pre>
<p><img src="figures/09_MC_inf_estimacao/unnamed-chunk-9-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Note que a média aparada é um estimador não viesado para a média populacional, portanto <span class="math inline">\(\text{EQM}[\theta] = \text{Var}[\theta] = \text{Var}[X]/n\)</span>, que é igual a <span class="math inline">\(1/20 = 0.05\)</span>, o que mostra que nossa estimativa está próxima.</p>
<p>Repare que a mediana também é uma média aparada: ela “apara” todos os valores das caudas menos um (quando <span class="math inline">\(n\)</span> for ímpar), ou dois (quando <span class="math inline">\(n\)</span> for par), e calcula a média. Portanto, podemos reptir o mesmo procedimento para a mediana.</p>
<pre class="r"><code>n &lt;- 20
N &lt;- 1000
tmean2 &lt;- numeric(N)
for (i in 1:N) {
    x &lt;- sort(rnorm(n))
    tmean2[i] &lt;- median(x)
}
## Estimativa pontual
(m.tmean2 &lt;- mean(tmean2))</code></pre>
<pre><code># [1] 0.00801335</code></pre>
<pre class="r"><code>## Variância
sum((tmean2 - m.tmean2)^2)/(N - 1)</code></pre>
<pre><code># [1] 0.06868125</code></pre>
<pre class="r"><code>## Erro padrão = desvio padrão da distribuição amostral
sqrt(sum((tmean2 - m.tmean2)^2))/(N - 1)</code></pre>
<pre><code># [1] 0.008291562</code></pre>
<pre class="r"><code>## EQM
(eqm2 &lt;- mean(tmean2^2))</code></pre>
<pre><code># [1] 0.06867678</code></pre>
<pre class="r"><code>hist(tmean2)</code></pre>
<p><img src="figures/09_MC_inf_estimacao/unnamed-chunk-10-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Agora podemos comparar qual dos dois estimadores é o melhor para a média populacional, através dos EQMs.</p>
<pre class="r"><code>## Qual dos dois possui menor EQM
eqm1 &lt;= eqm2</code></pre>
<pre><code># [1] TRUE</code></pre>
<pre class="r"><code>## Eficiência relativa
eqm1/eqm2</code></pre>
<pre><code># [1] 0.7342432</code></pre>
<p>Na última linha calculamos também a <strong>eficiência relativa</strong> entre dois estimadores, ou seja, a eficiência relativa de <span class="math inline">\(\hat{\theta}_1\)</span> em relação a <span class="math inline">\(\hat{\theta}_2\)</span> é <span class="math display">\[
\text{ER}[\hat{\theta}_1, \hat{\theta}_2] =
\frac{\text{Var}[\hat{\theta}_1]}{\text{Var}[\hat{\theta}_2]}
\]</span></p>
<p>Por esses resultados concluimos que ambos estimadores, média aparada de primeiro nível e mediana, são não viesados para estimar a média populacional <span class="math inline">\(\mu\)</span>, mas a média aparada é um estimador melhor, ou mais eficiente do que a mediana.</p>
</div>
<div id="exemplo-erro-padrão" class="section level2">
<h2><span class="header-section-number">6.4</span> Exemplo (erro padrão)</h2>
<p>Suponha <span class="math inline">\(X_1, X_2\)</span> são duas VAs iid de uma normal padrão. Usando simulação de Monte Carlo, obtenha uma estimativa de <span class="math inline">\(\text{E}(|X_1 - X_2|)\)</span>, e seu erro padrão.</p>
<p>Para estimar <span class="math inline">\(\theta = \text{E}(g(X_1, X_2)) = \text{E}(|X_1 - X_2|)\)</span>, baseado em <span class="math inline">\(N\)</span> amostras:</p>
<ol style="list-style-type: decimal">
<li>Gere as variáveis aleatórias <span class="math inline">\(\mathbb{x}^{(j)} = (x_1^{(j)}, x_2^{(j)})\)</span> da normal padrão, <span class="math inline">\(j = 1, \ldots, N\)</span>.</li>
<li>Calcule <span class="math inline">\(\hat\theta^{(j)} = g_j(x_1^{(j)}, x_2^{(j)}) = |x_1^{(j)} - x_2^{(j)}|\)</span>, e calcule a média.</li>
</ol>
<pre class="r"><code>N &lt;- 1000
g &lt;- numeric(N)
for (i in 1:N) {
    x &lt;- rnorm(2)
    g[i] &lt;- abs(x[1] - x[2])
}
(est &lt;- mean(g))</code></pre>
<pre><code># [1] 1.105322</code></pre>
<pre class="r"><code>hist(g)</code></pre>
<p><img src="figures/09_MC_inf_estimacao/unnamed-chunk-12-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Por integração, o resultado é <span class="math inline">\(\text{E}(|X_1 - X_2|) = 2/\sqrt{\pi} = 1.1284\)</span>.</p>
<p>Em uma amostra de Monte Carlo, o tamanho da amostra é <span class="math inline">\(N\)</span>, por isso, o erro padrão da estimativa será</p>
<pre class="r"><code>## Variância da distribuição amostral
sum((g - est)^2)/(N - 1)</code></pre>
<pre><code># [1] 0.6719454</code></pre>
<pre class="r"><code>var(g)</code></pre>
<pre><code># [1] 0.6719454</code></pre>
<pre class="r"><code>## Erro padrão = desvio padrão da distribuição amostral
sqrt(sum((g - est)^2))/N # viesado</code></pre>
<pre><code># [1] 0.02590895</code></pre>
<pre class="r"><code>sd(g)/sqrt(N)            # não viiesado</code></pre>
<pre><code># [1] 0.02592191</code></pre>
<p>Pode-se mostrar que o valor exato é <span class="math inline">\(ep = \sqrt{(2 - 4/\pi)/N} = 0.0269\)</span>.</p>
</div>
<div id="exemplo-estimativa-de-nível-de-confiança" class="section level2">
<h2><span class="header-section-number">6.5</span> Exemplo (estimativa de nível de confiança)</h2>
<p>Seja <span class="math inline">\(X_1, \ldots, X_n\)</span> uma amostra aleatória de uma <span class="math inline">\(\text{N}(\mu, \sigma^2)\)</span>, onde <span class="math inline">\(s^2\)</span> é a variância amostral. Considere o problema de estimar um <strong>intervalo de confiança</strong> para <span class="math inline">\(s^2\)</span>.</p>
<p>Do Teorema Central do Limite (TCL) sabemos que <span class="math inline">\(\bar{X} \sim \text{N}(\mu, \frac{\sigma^2}{n})\)</span>. Como não conhecemos <span class="math inline">\(\sigma^2\)</span>, usamos <span class="math inline">\(s^2\)</span> no lugar. Assim, temos que: <span class="math display">\[
\widehat{Var[\bar{X}]} = \frac{s^2}{n} \quad \text{e} \quad
\widehat{EP[\bar{X}]} = \frac{s}{\sqrt{n}}
\]</span></p>
<p>Para obter a variância de <span class="math inline">\(s^2\)</span>, precisamos lembrar que <span class="math display">\[
\frac{(n-1)s^2}{\sigma^2} \sim \chi_{(n-1)}^{2}
\]</span></p>
<p>Lembrando também que para uma variável aleatória <span class="math inline">\(X\)</span> com distribuição qui-quadrado com <span class="math inline">\(k\)</span> graus de liberdade, <span class="math inline">\(X \sim \chi^2_k\)</span>, temos <span class="math inline">\(E[X] = k\)</span>, e <span class="math inline">\(Var[X] = 2k\)</span>. Assim, calculamos a esperança como</p>
<p><span class="math display">\[\begin{align*}
E\left[ \frac{(n-1)s^2}{\sigma^2} \right ] &amp;= n-1 \\
\frac{(n-1)}{\sigma^2} E[s^2] &amp;= n-1 \\
E[s^2] &amp;= \frac{(n-1)\sigma^2}{(n-1)} \\
E[s^2] &amp;= \sigma^2
\end{align*}\]</span></p>
<p>Portanto, confirmamos que essa é uma estimativa não viesada. Da mesma forma, calculamos a variância como:</p>
<p><span class="math display">\[\begin{align*}
Var\left[ \frac{(n-1)s^2}{\sigma^2} \right ] &amp;= 2(n-1) \\
\frac{(n-1)^2}{\sigma^4} Var[s^2] &amp;= 2(n-1) \\
Var[s^2] &amp;= \frac{2(n-1)\sigma^4}{(n-1)^2} \\
Var[s^2] &amp;= \frac{2\sigma^4}{n-1} = \frac{2(\sigma^2)^2}{n-1}
\end{align*}\]</span></p>
<p>Como usamos <span class="math inline">\(s^2\)</span> no lugar de <span class="math inline">\(\sigma^2\)</span>, temos então que</p>
<p><span class="math display">\[
\widehat{Var[s^2]} = \frac{2(s^2)^2}{n-1}
\]</span></p>
<p>O erro-padrão de <span class="math inline">\(s^2\)</span> é então a raíz quadrada desta variância, ou seja,</p>
<p><span class="math display">\[
\widehat{EP[s^2]} = \sqrt{\widehat{Var[s^2]}} =
  \sqrt{\frac{2(s^2)^2}{n-1}} = s^2 \sqrt{\frac{2}{n-1}}
\]</span></p>
<p>Um intervalo de confiança <strong>unilateral</strong> de <span class="math inline">\(100(1-\alpha)\%\)</span> de confiança é dado por <span class="math display">\[
\left(0, \frac{(n-1)s^2}{\chi^2_{\alpha}} \right)
\]</span> onde <span class="math inline">\(\chi^2_{\alpha}\)</span> é o <span class="math inline">\(\alpha\)</span>-quantil de uma distribuição <span class="math inline">\(\chi^2 (n-1)\)</span>. Se a população amostrada é normal com variância <span class="math inline">\(\sigma^2\)</span>, então a probabilidade de que o intervalo contenha <span class="math inline">\(\sigma^2\)</span> é <strong>exatamente</strong> <span class="math inline">\(1-\alpha\)</span>. Por exemplo, para <span class="math inline">\(\alpha = 0.05\)</span>, <span class="math display">\[
\begin{align*}
P\left(\frac{(n-1)s^2}{\sigma^2} &gt; \chi^2_{.05}(n-1) \right) &amp;= 0.95 \\
P\left(\frac{(n-1)s^2}{\chi^2_{.05}(n-1)} &gt; \sigma^2 \right) &amp;= 0.95
\end{align*}
\]</span></p>
<p>Por exemplo, o cáculo do limite superior do intervalo de <span class="math inline">\(95\%\)</span> de confiança para uma amostra de tamanho <span class="math inline">\(n=20\)</span> de uma <span class="math inline">\(\text{N}(0, 4)\)</span> é</p>
<pre class="r"><code>n &lt;- 20
alpha &lt;- .05
x &lt;- rnorm(n, mean = 0, sd = 2)
(UCL &lt;- (n - 1) * var(x) / qchisq(alpha, df = n - 1))</code></pre>
<pre><code># [1] 5.331845</code></pre>
<p>que contém o verdadeiro valor <span class="math inline">\(\sigma^2 = 4\)</span>. Se repetirmos esse processo várias vezes, esperamos então que aproximadamente <span class="math inline">\(95\%\)</span> das vezes, o intervalo contenha o verdadeiro valor de <span class="math inline">\(\sigma^2\)</span>, <strong>assumindo que a população amostrada é normal</strong> com variância <span class="math inline">\(\sigma^2\)</span>.</p>
<p>De maneira geral, um algoritmo para calcular o nível de confiança <strong>empírico</strong> para uma estimativa de algum parâmetro <span class="math inline">\(\theta\)</span> é:</p>
<ol style="list-style-type: decimal">
<li>Para cada repetição, indexada em <span class="math inline">\(j = 1, \ldots, N\)</span>
<ol style="list-style-type: lower-alpha">
<li>Gere a <span class="math inline">\(j\)</span>-ésima amostra aleatória, <span class="math inline">\(x_1^{(j)}, \ldots, x_n^{(j)}\)</span></li>
<li>Calcule o intervalo de confiança <span class="math inline">\(C_j\)</span> para a <span class="math inline">\(j\)</span>-ésima amostra</li>
<li>Calcule <span class="math inline">\(y_j = I(\theta \in C_j)\)</span> para a <span class="math inline">\(j\)</span>-ésima amostra</li>
</ol></li>
<li>Calcule o nível de confiança empírico <span class="math inline">\(\bar{y} = \frac{1}{N}\sum_{j=1}^{N} y_j\)</span></li>
</ol>
<p>A proporção amostral de intervalos que contém <span class="math inline">\(\theta\)</span> é então uma estimativa de Monte Carlo do verdadeiro nível de confiança <span class="math inline">\((1-\alpha)\)</span>.</p>
<p>(Note aqui o uso da função <code>replicate()</code> no lugar do <code>for()</code>).</p>
<pre class="r"><code>n &lt;- 20
m &lt;- 1000
alpha &lt;- .05
UCL &lt;- replicate(m, expr = {
    x &lt;- rnorm(n, mean = 0, sd = 2)
    (n - 1) * var(x) / qchisq(alpha, df = n - 1)
})
## Número de intervalos que contém sigma^2 = 4
sum(UCL &gt; 4)</code></pre>
<pre><code># [1] 963</code></pre>
<pre class="r"><code>## Nível de confiança empírico
sum(UCL &gt; 4)/N</code></pre>
<pre><code># [1] 0.963</code></pre>
<pre class="r"><code>mean(UCL &gt; 4)</code></pre>
<pre><code># [1] 0.963</code></pre>
<p>Veja que o nível de confiança empírico é muito próximo do nível de confiança teórico, de <span class="math inline">\(95\%\)</span>. Para 100 intervalos calculados, podemos visualizar o procedimento:</p>
<pre class="r"><code>UCL.sim &lt;- replicate(100, expr = {
    x &lt;- rnorm(n, mean = 0, sd = 2)
    (n - 1) * var(x) / qchisq(alpha, df = n - 1)
})
plot(NULL, NULL, xlim = c(0, 100), ylim = c(0, max(UCL.sim)), ylab = &quot;&quot;)
segments(1:100, 0, 1:100, UCL.sim)
abline(h = 4, col = 2)</code></pre>
<p><img src="figures/09_MC_inf_estimacao/unnamed-chunk-16-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Sabemos que o cálculo de intervalos de confiança para a variância é bastante sensível à fugas da normalidade. Ou seja, se a população amostrada não for normal, então o cálculo do intervalo de confiança possivelmente será afetado, refletindo no nível de confiança.</p>
<p>Por exemplo, suponha que ao invés de normal, os dados foram obtidos a partir de uma população que segue uma distribuição <span class="math inline">\(\chi^2\)</span> com 2 graus de liberdade, que também possui variância 4, mas claramente não é normal.</p>
<pre class="r"><code>curve(dchisq(x, df = 2), to = 10)</code></pre>
<p><img src="figures/09_MC_inf_estimacao/unnamed-chunk-17-1.png" width="80%" style="display: block; margin: auto;" /></p>
<p>Podemos repetir o procedimento acima, substituindo as amostras de <span class="math inline">\(X\)</span> da normal pela <span class="math inline">\(\chi^2(2)\)</span> e verificar qual seria então o nível de confiança empírico.</p>
<pre class="r"><code>n &lt;- 20
m &lt;- 1000
alpha &lt;- .05
UCL &lt;- replicate(m, expr = {
    x &lt;- rchisq(n, df = 2)
    (n - 1) * var(x) / qchisq(alpha, df = n - 1)
})
## Número de intervalos que contém sigma^2 = 4
sum(UCL &gt; 4)</code></pre>
<pre><code># [1] 766</code></pre>
<pre class="r"><code>## Nível de confiança empírico
sum(UCL &gt; 4)/N</code></pre>
<pre><code># [1] 0.766</code></pre>
<pre class="r"><code>mean(UCL &gt; 4)</code></pre>
<pre><code># [1] 0.766</code></pre>
<p>Veja que, embora estamos calculando intervalos <strong>teóricos</strong> de <span class="math inline">\(95\%\)</span>, o nível de confiança é na verdade bem mais baixo, o que pode levar à conclusões equivocadas nesse caso onde a população não é normal.</p>
<p>Visualmente temos:</p>
<pre class="r"><code>UCL.sim &lt;- replicate(100, expr = {
    x &lt;- rchisq(n, df = 2)
    (n - 1) * var(x) / qchisq(alpha, df = n - 1)
})
plot(NULL, NULL, xlim = c(0, 100), ylim = c(0, max(UCL.sim)), ylab = &quot;&quot;)
segments(1:100, 0, 1:100, UCL.sim)
abline(h = 4, col = 2)</code></pre>
<p><img src="figures/09_MC_inf_estimacao/unnamed-chunk-19-1.png" width="80%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="distribuição-amostral-da-média" class="section level1">
<h1><span class="header-section-number">7</span> Distribuição amostral da média</h1>
<pre class="r"><code>##======================================================================
## Script Teorema do Limite Central - TLC
##======================================================================

set.seed(2014)
## Grafico de convergência de 4 distribuições de acordo com o TLC
# Normal(500, 1000)
norm &lt;- rnorm(500, mean = 500, sd = 100)
# Uniforme[200,800]
unif &lt;- runif(500, min = 200, max = 800)
# Exponencial(1)
expo &lt;- rexp(500, rate = 1)
# Poisson(2)
pois &lt;- rpois(500, lambda = 2)
# n amostral
n &lt;- c(5, 25, 100)
# m = número de amostras aleatórias de tamanho n
m &lt;- 500
# vetor temporario para receber os valores de média
temp &lt;- numeric(m)

## Limites para cada distribuicao
xlim.norm &lt;- c(150, 800)
xlim.unif &lt;- c(200, 800)
xlim.expo &lt;- c(0, 6)
xlim.pois &lt;- c(0, 7)

## pdf(&quot;img/dist_amostrais.pdf&quot;, width = 8, height = 8)
par(mfrow = c(4, 4))
# Distribuição Normal
hist(norm, freq = TRUE, main = &quot;População - N = 500&quot;,
     include.lowest = TRUE, right = FALSE, ylab = &quot;Frequência&quot;,
     col = &quot;lightgray&quot;, xlab = &quot;Normal&quot;, xlim = xlim.norm)
for(i in 1:3){
    for(j in 1:m){
        temp[j] &lt;- mean(sample(norm, size = n[i], replace = TRUE))
    }
    hist(temp, freq = TRUE, main = paste(&quot;n = &quot;, n[i]),
         include.lowest = TRUE, right = FALSE, ylab = &quot;Frequência&quot;,
         xlab = &quot;Médias amostrais&quot;, xlim = xlim.norm)
}
# Distribuição Uniforme
hist(unif, freq = TRUE, main = &quot;População - N = 500&quot;,
     include.lowest = TRUE, right = FALSE, xlim = xlim.unif,
     col = &quot;lightgray&quot;, xlab = &quot;Uniforme&quot;, ylab = &quot;Frequência&quot;)
for(i in 1:3){
    for(j in 1:m){
        temp[j] &lt;- mean(sample(unif, size = n[i], replace = TRUE))
    }
    hist(temp, freq = TRUE, main = paste(&quot;n = &quot;, n[i]),
         include.lowest = TRUE, right = FALSE, ylab = &quot;Frequência&quot;,
         xlab = &quot;Médias amostrais&quot;, xlim = xlim.unif)
}
# Distribuição Exponencial
hist(expo, freq = TRUE, main = &quot;População - N = 500&quot;,
     include.lowest = TRUE, right = FALSE, xlim = xlim.expo,
     col = &quot;lightgray&quot;, xlab = &quot;Exponencial&quot;, ylab = &quot;Frequência&quot;)
for(i in 1:3){
    for(j in 1:m){
        temp[j] &lt;- mean(sample(expo, size = n[i], replace = TRUE))
    }
    hist(temp, freq = TRUE, main = paste(&quot;n = &quot;, n[i]),
         include.lowest = TRUE, right = FALSE, ylab = &quot;Frequência&quot;,
         xlab = &quot;Médias amostrais&quot;, xlim = xlim.expo)
}
# Distribuição Poisson
hist(pois, freq = TRUE, main = &quot;População - N = 500&quot;,
     include.lowest = TRUE, right = FALSE, xlim = xlim.pois,
     col = &quot;lightgray&quot;, xlab = &quot;Poisson&quot;, ylab = &quot;Frequência&quot;)
for(i in 1:3){
    for(j in 1:m){
        temp[j] &lt;- mean(sample(pois, size = n[i], replace = TRUE))
    }
    hist(temp, freq = TRUE, main = paste(&quot;n = &quot;, n[i]),
         include.lowest = TRUE, right = FALSE, ylab = &quot;Frequência&quot;,
         xlab = &quot;Médias amostrais&quot;, xlim = xlim.pois)
}
par(mfrow = c(1, 1))
## dev.off()</code></pre>
<!--
# Teste de hipótese de Monte Carlo

- **Erro Tipo I**: rejeitar $H_0$, quando $H_0$ é verdadeira.
- **Erro Tipo II**: não rejeitar $H_0$ quando $H_0$ é falsa.

Definimos por $\alpha$ e $\beta$ as probabilidades de cometer os erros
do tipo I e II:

- $\alpha = P(\text{erro tipo I}) = P(\text{rejeitar } H_0 \, | \, H_0
  \text{ verdadeira})$
- $\beta = P(\text{error tipo II}) = P(\text{não rejeitar } H_0 \, | \, H_0
  \text{ falsa})$

## Cálculo da taxa empírica do erro do tipo I {-}


```r
## Obtém o valor da estatística t do teste de Student para a média de
## uma população. Assume que a distribuição de X seja normal.
simula0 <- function(n, mu0, sig0){
    X <- rnorm(n, mean=mu0, sd=sig0)
    T <- (mean(X)-mu0)/(sqrt(var(X)/n))
    return(T)
}

simula0(n=10, mu0=0, sig0=1)
```

```
# [1] 0.3698479
```

```r
t <- replicate(10000, simula0(n=10, mu0=0, sig0=1))

## Comparação por distribuições acumuladas.
plot(ecdf(t), xlim=c(-5, 5))
curve(pt(x, df=10-1), add=TRUE, col=2)
curve(pnorm(x), add=TRUE, col=3)
```

<img src="figures/09_MC_inf_estimacao/unnamed-chunk-21-1.png" width="80%" style="display: block; margin: auto;" />

```r
## Comparação pela densidade.
plot(density(t), xlim=c(-5, 5))
curve(dt(x, df=10-1), add=TRUE, col=2)
curve(dnorm(x), add=TRUE, col=3)
```

<img src="figures/09_MC_inf_estimacao/unnamed-chunk-21-2.png" width="80%" style="display: block; margin: auto;" />

```r
## p-valor da simulação.
sum(abs(t) >= qt(0.975, df=10-1))/length(t)
```

```
# [1] 0.049
```

```r
## Distribuição da estatística com afastamento dos pressupostos sobre a
## distribuição da população (X) que não tem distribuição normal.
simula1 <- function(n, mu0=1){
    X <- rexp(n, 1)
    T <- (mean(X)-mu0)/(sqrt(var(X)/n))
    return(T)
}

## Tamanho da amostra da exponencial
n <- 5
t <- replicate(10000, simula1(n=n))

plot(ecdf(t), xlim=c(-5, 5))
curve(pt(x, df=n-1), add=TRUE, col=2)
curve(pnorm(x), add=TRUE, col=3)
```

<img src="figures/09_MC_inf_estimacao/unnamed-chunk-21-3.png" width="80%" style="display: block; margin: auto;" />

```r
## p-valor real vs nível se significância nominal.
sum(abs(t) >= qt(0.975, df=n-1))/length(t)
```

```
# [1] 0.1162
```

```r
## O que aconteceria se o tamanho da amostra da exponanecial fosse
## maior?
```

<!-- ## Testes via simulação de Monte Carlo -->
<!-- ### Nível descritivo {-} -->
<!-- - Em geral, $\alpha$ é pré-fixado para construir a regra de decisão. -->
<!-- - Uma alternativa é deixar em aberto a escolha de $\alpha$ para quem for -->
<!-- tomar a decisão. -->
<!-- - A ideia é calcular, **supondo que a hipóese nula é verdadeira**, a -->
<!-- probabilidade de se obter estimativas mais extremas do que aquela -->
<!-- fornecida pela amostra. -->
<!-- - Essa probabilidade é chamada de **nível descritivo**, denotada por -->
<!-- $\alpha^*$ (ou $P$-valor). -->
<!-- - Valores pequenos de $\alpha^*$ evidenciam que a hipótese nula é falsa. -->
<!-- - O conceito de "pequeno" fica para quem decide qual $\alpha$ deve usar -->
<!-- para comparar com $\alpha^*$. -->
<!-- Para **testes unilaterais**, sendo $H_0: \mu = \mu_0$, a expressão de -->
<!-- $\alpha^*$ depende da hipótese alternativa: -->
<!-- \begin{align*} -->
<!-- \alpha^* &= P(\bar{X} < \bar{x}_{obs} \, | \, H_0 \text{ verdadeira}) \quad -->
<!-- \text{para } H_a: \mu < \mu_0 \\ -->
<!-- \alpha^* &= P(\bar{X} > \bar{x}_{obs} \, | \, H_0 \text{ verdadeira}) \quad -->
<!-- \text{para } H_a: \mu > \mu_0 -->
<!-- \end{align*} -->
<!-- Para **testes bilaterais**, temos $H_0: \mu = \mu_0$ contra $H_0: \mu -->
<!-- \neq \mu_0$, a definição do nível descritivo depende da relação entre -->
<!-- $\bar{x}_{obs}$ e $\mu_0$: -->
<!-- \begin{align*} -->
<!-- \alpha^* &= 2 \times P(\bar{X} < \bar{x}_{obs} \, | \, H_0 \text{ -->
<!-- verdadeira}) \quad \text{se }  \bar{x}_{obs} < \mu_0 \\ -->
<!-- \alpha^* &= 2 \times P(\bar{X} > \bar{x}_{obs} \, | \, H_0 \text{ -->
<!-- verdadeira}) \quad \text{se }  \bar{x}_{obs} > \mu_0 \\ -->
<!-- \end{align*} -->
<!-- Como estamos calculando a probabilidade para apenas uma das caudas, -->
<!-- então esse valor é multiplicado por 2. -->
<p>–&gt;</p>
</div>

<center>
  <hr width="100%" size="3px">
  <p> <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.pt_BR">
      <img src="https://i.creativecommons.org/l/by-nc-sa/4.0/80x15.png" alt="Licença Creative Commons 4.0"> </a>
  </p>
  <p> <font size="2"> Este conteúdo
      está disponível por meio da Licença Creative Commons 4.0 </font>
  </p>
</center>


</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = false;
    options.smoothScroll = false;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
