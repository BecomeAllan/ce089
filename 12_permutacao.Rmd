---
title: "Testes de permutação (ou aleatorização)"
# subtitle: "Jackknife"
author: "Fernando P. Mayer"
bibliography: ref.bib
output:
  html_document:
    number_sections: true
    toc_depth: 3
---

```{r, cache=FALSE, include=FALSE}
source("setup_knitr.R")
opts_chunk$set(fig.path = "figures/12_permutacao/")
```

# Introdução

**Justificativas**

- Métodos computacionalmente intensivos para inferência
estatística são usados quando as abordagens tradicionais não são
adequadas.
- Resultados assintóticos em pequenas amostras.
- Violação de pressupostos.
- Não existência de mecanísmos de inferência específicos.
- Tais métodos se baseiam em reamostragem e/ou simulação.
- Podem ser aplicados em muitos contextos.

**Testes de Aleatorização**

- Abordagem baseada em permutação das observações
(*permutation tests*).
- São considerados testes **livre de distribuição**.
- Faz suposições sobre o processo gerador dos dados.
- Duas formas de cálculo da estatística de teste:
  - **Exaustiva**: no conjunto de todos os arranjos possíveis
  $\rightarrow$ distribuição amostral exata.
  - **Por reamostragem**: amostra do conjunto completo de arranjos com
    **reamostragem sem reposição**.
- IMPORTANTE: Sob a hipótese nula os dados são **permutáveis**.
- Esse é o principal conceito e requisito dos testes de
aleatorização.

**Limitações dos testes de aleatorização**

- Só podem ser usados para **hipóteses que envolvam comparações**
(trocar observações entre grupos) ou desalinhar registros (como em
correlação, por exemplo).
- Portanto, não podem ser usados para testar hipóteses sobre
parâmetros individuais.
- O teste de aleatorização exato de Fisher para a média é uma
alternativa para testar hipótese sobre a média considerando
população simétrica, porém, estritamente não é um teste de
aleatorização.

De acordo com Manly (2006):

- Compara o valor da estatística com aquele obtido da distribuição
gerada pela **permutação dos valores observados**.
- São úteis pois permitem o usuário definir a estatística de teste
mais apropriada.
- **Não necessariamente os resultados podem ser extrapolados para a
população**.
- Testes de aleatorização são exatos: fonece um nível de
significância que é igual ou inferior ao nível nominal.
- Duas estatísticas são equivalente se elas dão o mesmo nível de
significância em testes de aleatorização.
- Testes de aleatorização e tradicionais darão similar nível de
significância se as suposições do último forem atendidas.

# Exemplos

## Exemplos simples

### Diferença entre médias de dois grupos

```{r, cache=TRUE}
## Dados observados
x <- c(4.1, 8.3, 2.9, 10.8, 9.5)
y <- c(3.7, 5.1, 1.0, 7.7, 8.9)
da <- data.frame(vals = c(x, y),
                 id = rep(c("x", "y"), each = 5))
da

## Compara médias
with(da, tapply(vals, id, mean))
(obsdiff <- with(da, abs(diff(tapply(vals, id, mean)))))

## Teste-t tradicional
t.test(vals ~ id, data = da, var.equal = TRUE)

## Número possível de permutações por grupo
factorial(length(x))
factorial(length(y))

## A permutação dentro de cada grupo não faz sentido, pois as médias não
## serão alteradas
xperm <- gtools::permutations(n = length(x), r = length(x), v = x)
str(xperm)
sort(x)
head(xperm)
tail(xperm)
yperm <- gtools::permutations(n = length(y), r = length(y), v = y)
str(yperm)
sort(y)
head(yperm)
tail(yperm)
## Diferença entre médias para todas as permutações
xydiff <- numeric(nrow(xperm))
for(i in 1:nrow(xperm)) {
    xydiff[i] <- mean(xperm[i, ]) - mean(yperm[i, ])
}
str(xydiff)
summary(xydiff)

## Portanto, a permutação deve ser feita entre os grupos, ou seja,
## alternando todos os valores possíveis entre os dois grupos
xy <- c(x, y)
## Número de permutações
factorial(length(xy))
xyperm <- gtools::permutations(n = length(xy), r = length(xy), v = xy)
str(xyperm)
sort(xy)
head(xyperm)
tail(xyperm)

## Calcula a diferença média para todas as permutações possíveis
library(future.apply)
plan(multicore, workers = 4)
xydiff <- future_apply(matrix(1:nrow(xyperm)), 1, function(i) {
    mean(xyperm[i, 1:5]) - mean(xyperm[i, 6:10])
})
str(xydiff)
summary(xydiff)
hist(xydiff)
abline(v = obsdiff, col = 2)

## P-valor do teste.
2 * sum(xydiff >= obsdiff)/length(xydiff)
t.test(vals ~ id, data = da, var.equal = TRUE)$p.value

## Usando pacotes
library(coin)
oneway_test(vals ~ factor(id), data = da)
oneway_test(vals ~ factor(id), data = da,
            distribution = approximate(nresample = 10000))
library(perm)
permTS(vals ~ id, data = da)
```

Mesmo em um caso simples como, esse, onde n = 10, já vimos que o número
total de permutações possíveis pode ser muito grande, o que faz com que
esse processo fique inviável computacionalmente. A ideia então é fazer
um grande número de permutações aleatórias e fazer o mesmo cálculo. Isso
pode ser feito retirando-se amostra COM REPOSIÇÃO da amostra conjunta
(concatenando os dois grupos) Usando amostras sem reposição

```{r, cache=TRUE}
N <- 10000
xydiff <- future_replicate(
    N, diff(tapply(sample(xy), da$id, mean))
)
str(xydiff)
summary(xydiff)
hist(xydiff)
abline(v = obsdiff, col = 2)

## P-valor do teste.
2 * sum(xydiff >= obsdiff)/length(xydiff)
t.test(vals ~ id, data = da, var.equal = TRUE)$p.value
coin::oneway_test(vals ~ factor(id), data = da)
perm::permTS(vals ~ id, data = da)
```

### Teste para correlação

Usando o mesmo exemplo, mas agora calculando a correlação entre os
grupos. NOTE que é necessário usar a correlação (de postos) de Spearman.

```{r, cache=TRUE}
## Correlações observadas
cor(x, y, method = "pearson")
cor(x, y, method = "kendall")
(obscor <- cor(x, y, method = "spearman"))

## Calcula a diferença média para todas as permutações possíveis
xycor <- future_apply(matrix(1:nrow(xyperm)), 1, function(i) {
    cor(xyperm[i, 1:5], xyperm[i, 6:10], method = "spearman")
})
str(xycor)
summary(xycor)
hist(xycor)
abline(v = obscor, col = 2)

## P-valor do teste.
2 * sum(xycor >= obscor)/length(xycor) # teste exato
cor.test(x, y,  method = "pearson")$p.value
cor.test(x, y,  method = "kendall")$p.value
cor.test(x, y,  method = "spearman")$p.value
coin::spearman_test(x ~ y,
              distribution = approximate(nresample = 10000))

## Usa amostragem SEM REPOSIÇÃO
N <- 100000
n <- length(xy)
xycor <- future_replicate(N, {
    ip <- sample(1:n, size = n/2, replace = FALSE)
    xp <- xy[ip]
    yp <- xy[-ip]
    cor(xp, yp, method = "spearman")
})
str(xycor)
summary(xycor)
hist(xycor)
abline(v = obscor, col = 2)

## P-valor do teste.
2 * sum(xycor >= obscor)/length(xycor) # teste aproximado
cor.test(x, y,  method = "pearson")$p.value
cor.test(x, y,  method = "kendall")$p.value
cor.test(x, y,  method = "spearman")$p.value
coin::spearman_test(x ~ y,
              distribution = approximate(nresample = 10000))
```

## Exemplo aplicado: correlação

```{r, cache=TRUE}
data(law, package = "bootstrap")
str(law)
plot(law$LSAT, law$GPA)
x <- law$LSAT
y <- law$GPA
(obscor <- cor(x, y, method = "spearman"))

## Impossível fazer com todas as permutações
factorial(nrow(law))

## Usa amostragem SEM REPOSIÇÃO
N <- 1000000
xy <- c(x, y)
n <- length(xy)
xycor <- future_replicate(N, {
    ip <- sample(1:n, size = n/2, replace = FALSE)
    xp <- xy[ip]
    yp <- xy[-ip]
    cor(xp, yp, method = "spearman")
})
str(xycor)
summary(xycor)
hist(xycor)
abline(v = obscor, col = 2)

## P-valor do teste.
2 * sum(xycor >= obscor)/length(xycor) # teste aproximado
cor.test(x, y,  method = "pearson")$p.value
cor.test(x, y,  method = "kendall")$p.value
cor.test(x, y,  method = "spearman")$p.value
coin::spearman_test(x ~ y,
              distribution = approximate(nresample = 100000))
```

## Exemplo das aulas anteriores

```{r}
## Exemplo adaptado de Manly (1997)
## Comparação do comprimento da mandíbula de chacais machos e fêmeas
set.seed(2)
machos <- c(120, 107, 110, 116, 114, 111, 113, 117, 114, 112)
## Simula diferença para as femeas
femeas <- rnorm(10, mean(machos) - 2, sd = sd(machos))
da <- data.frame(comp = c(machos, femeas),
                 sexo = c(rep("M", 10), rep("F", 10)))
densityplot(~comp, groups = sexo, data = da, auto.key = TRUE)
## Média por sexo
tapply(da$comp, da$sexo, mean)
## Diferença das médias
diff(tapply(da$comp, da$sexo, mean))

## Média de cada sexo
(m1 <- mean(machos))
(m2 <- mean(femeas))
## Diferença entre as médias amostrais
(med.amostral <- m1 - m2)
## Calcula o desvio padrão ponderado
n1 <- length(machos)
v1 <- var(machos)
n2 <- length(femeas)
v2 <- var(femeas)
(s.pond <- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2)/(n1 + n2 - 2)))

## Teste de hipótese para
## H0: mu1 <= mu2
## Ha: mu1 > mu2
mu0 <- 0
t.test(x = machos, y = femeas, alternative = "greater",
       var.equal = TRUE, mu = mu0)
## Estatística de teste
(tcalc <- (m1 - m2)/(s.pond * sqrt(1/n1 + 1/n2)))
## Valor crítico
(tcrit <- qt(.025, df = n1 + n2 - 2, lower.tail = FALSE))
## p-valor
pt(tcalc, df = n1 + n2 - 2, lower.tail = FALSE)

## Teste por simulação via _permutação_
N <- 10000
## Se a hipótese nula é verdadeira, então o comprimento das mandíbulas
## de machos e fêmeas são provenientes da mesma poplação, e portanto
## podem ser pensados como uma única amostra.
amostra <- c(machos, femeas)
## Amostra SEM REPOSIÇÃO os 20 valores, e atribui aleatoriamente 10 para
## cada grupo (macho ou fêmea). Se forem de fato da mesma população,
## então as diferenças entre as médias devem ser próximas de zero.
am <- replicate(
    N, diff(tapply(sample(amostra, replace = FALSE), da$sexo, mean))
)
## Visualização
hist(am, main = "Distribuição amostral")
abline(v = med.amostral, col = 2)
## p-valor empírico
sum(am >= med.amostral)/N
```

```{r}
## Exemplo adaptado de Manly (1997)
## Comparação do comprimento da mandíbula de chacais machos e fêmeas
machos <- c(120, 107, 110, 116, 114, 111, 113, 117, 114, 112)
femeas <- c(110, 111, 107, 108, 110, 105, 107, 106, 111, 111)
da <- data.frame(comp = c(machos, femeas),
                 sexo = c(rep("M", 10), rep("F", 10)))
densityplot(~comp, groups = sexo, data = da, auto.key = TRUE)
## Média por sexo
tapply(da$comp, da$sexo, mean)
## Diferença das médias
diff(tapply(da$comp, da$sexo, mean))

## Média de cada sexo
(m1 <- mean(machos))
(m2 <- mean(femeas))
## Diferença entre as médias amostrais
(med.amostral <- m1 - m2)
## Calcula o desvio padrão ponderado
n1 <- length(machos)
v1 <- var(machos)
n2 <- length(femeas)
v2 <- var(femeas)
(s.pond <- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2)/(n1 + n2 - 2)))

## Teste de hipótese para
## H0: mu1 <= mu2
## Ha: mu1 > mu2
mu0 <- 0
t.test(x = machos, y = femeas, alternative = "greater",
       var.equal = TRUE, mu = mu0)
## Estatística de teste
(tcalc <- (m1 - m2)/(s.pond * sqrt(1/n1 + 1/n2)))
## Valor crítico
(tcrit <- qt(.025, df = n1 + n2 - 2, lower.tail = FALSE))
## p-valor
pt(tcalc, df = n1 + n2 - 2, lower.tail = FALSE)

## Teste por simulação via _permutação_
N <- 10000
## Se a hipótese nula é verdadeira, então o comprimento das mandíbulas
## de machos e fêmeas são provenientes da mesma população, e portanto
## podem ser pensados como uma única amostra.
amostra <- c(machos, femeas)
## Amostra SEM REPOSIÇÃO os 20 valores, e atribui aleatoriamente 10 para
## cada grupo (macho ou fêmea). Se forem de fato da mesma população,
## então as diferenças entre as médias devem ser próximas de zero.
am <- replicate(
    N, diff(tapply(sample(amostra, replace = FALSE), da$sexo, mean))
)
## Visualização
hist(am, main = "Distribuição amostral")
abline(v = med.amostral, col = 2)
## p-valor empírico
sum(am >= med.amostral)/N
```

## Índice de Moran (correlação espacial)

O índice de Moran é uma medida que avalia a dependência espacial entre
observações, através de uma medida de correlção que considera os "pesos"
entre observações vizinhas (mais próximas). Valores em locais mais
próximos tendem a influenciar mais do que os valores de locais mais
distantes.

O índice ($I$) de Moran é calculado por
$$
I = \frac{n}{\sum_{i=1}^n (x_i - \bar{x})^2} \frac{\sum_{i=1}^n
\sum_{j=1}^n w_{ij}(x_i - \bar{x})(x_j - \bar{x})}{\sum_{i=1}^n
\sum_{j=1}^n w_{ij}}
$$

```{r}
## Índice de Moran para medir dependência espacial.

## Coordenadas dos eventos em uma malha regular 8 x 8.
x <- 1:8
y <- 1:8

## Construção da matriz de pesos que determina a vizinhança entre
## observações.
ind <- expand.grid(i = 1:length(x),
                   j = 1:length(y))
plot(ind)

##  Função que determina o peso entre duas localizações na malha.
f <- function(i, j) {
    u <- min(3, sum(abs(ind[i, ] - ind[j, ])))
    w <- c(0, 1, sqrt(1/2), 0)[u + 1]
    return(w)
}

##  Cria os pesos, matriz (8^2) x (8^2) = 64 x 64.
w <- matrix(0, nrow = nrow(ind), ncol = nrow(ind))
for (i in 1:nrow(ind)) {
    for (j in 1:nrow(ind)) {
        w[i, j] <- f(i, j)
    }
}

##  Normaliza.
w <- w/sum(w)

## Gráfico. Valores claros indicam maior peso entre observações.
image(w, asp = 1)

## Lógica do índica de Moran: correlação entre valores observados e
## média dos vizinhos. Exemplo com valores simulados.
xx <- rnorm(64)
cor(cbind("Valores observados" = xx,
          "Média dos vizinhos" = as.vector(xx %*% w)))

## Índice de Moran
moran <- function(x, w) {
    n <- length(x)
    xbar <- mean(x)
    dx <- x - xbar
    xi <- rep(dx, each = n)
    xj <- rep(dx)
    xixj <- xi * xj
    pm <- matrix(xixj, ncol = n)
    pmw <- pm * w
    spmw <- sum(pmw)
    smw <- sum(w)
    sw  <- spmw / smw
    vr <- n / sum(dx^2)
    MI <- vr * sw
    return(MI)
}

## Moran para os dados simulados
moran(xx, w)
replicate(10, moran(sample(xx), w))
```

A ideia do teste de permutação, é trocar de lugar as observações e
calcular o índice de Moran, mantendo a matriz de pesos fixa. Se não
houver dependência espacial, então qualquer observação poderia estar em
qualquer lugar. Com isso, o valor calculado do índice de Moran pode ser
comparado com a distribuição dos índices de Moran calculados para
observações permutadas. Se o valor observado for extremo, indica que
deve haver correlação espacial. Se o observado estiver no centro (ou
próximo do centro) da distribuição, então não há evidências de
correlação espacial.

```{r, cache=TRUE}
## Teste de permutação com saída gráfica.
ppt <- function(z, w, N = 10000, stat, ...) {
    ## Índice de Moran por reamostragem.
    sim <- replicate(N, moran(sample(z), w))
    ## Determina o p-valor.
    p.value <- mean((all <- c(stat, sim)) >= stat)
    ## Histograma da distribuição empírica sob H_0.
    hist(sim,
         sub = paste("p =", round(p.value, 4)),
         xlim = range(all), ...)
    abline(v = stat, col = "#903030", lty = 3, lwd = 2)
    return(p.value)
}

## Observações simuladas.
set.seed(17)
par(mfrow = c(2, 3))

## Dados com dependência espacial --------------------------------------
## Indução de autocorrelação por meio de uma tendência.
z <- matrix(rexp(length(x) * length(y),
                 outer(x, y^2)),
            length(x))
image(log(z), main = "Com dependência")

cor(cbind("Valores observados" = as.vector(z),
          "Média dos vizinhos" = as.vector(as.vector(z) %*% w)))

## Índice de Moran com dados originais.
(stat <- moran(z, w))

hist(z)
ppt(z, w, stat = stat, main = "I de Moran", xlab = "I")

## Teste usando spdep
spdep::moran.test(z, spdep::mat2listw(w))
## De help(moran.test):
## The assumptions underlying the test are sensitive to the form of the
## graph of neighbour relationships and other factors, and results may
## be checked against those of moran.mc permutations
spdep::moran.mc(z, spdep::mat2listw(w), nsim = 10000)

## Dados sem dependência espacial --------------------------------------
## Geração de de um conjunto de dados sob hipótese nula.
z <- matrix(rnorm(length(x) * length(y), 0, 1/2), length(x))
image(z, main = "Sem dependência")

cor(cbind("Valores observados" = as.vector(z),
          "Média dos vizinhos" = as.vector(as.vector(z) %*% w)))

# Índice de Moran com dados originais.
(stat <- moran(z, w))

hist(z)
ppt(z, w, stat = stat, main = "I de Moran", xlab = "I")
par(mfrow = c(1, 1))

## Teste usando spdep
spdep::moran.test(z, spdep::mat2listw(w))
spdep::moran.mc(z, spdep::mat2listw(w), nsim = 10000)
```
