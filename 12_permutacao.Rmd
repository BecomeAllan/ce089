---
title: "Testes de permutação (ou aleatorização)"
# subtitle: "Jackknife"
author: "Fernando P. Mayer"
bibliography: ref.bib
output:
  html_document:
    number_sections: true
    toc_depth: 3
---

```{r, cache=FALSE, include=FALSE}
source("setup_knitr.R")
opts_chunk$set(fig.path = "figures/12_permutacao/")
```

# Introdução

**Justificativas**

- Métodos computacionalmente intensivos para inferência
estatística são usados quando as abordagens tradicionais não são
adequadas.
- Resultados assintóticos em pequenas amostras.
- Violação de pressupostos.
- Não existência de mecanísmos de inferência específicos.
- Tais métodos se baseiam em reamostragem e/ou simulação.
- Podem ser aplicados em muitos contextos.

**Testes de Aleatorização**

- Abordagem baseada em permutação das observações
(*permutation tests*).
- São considerados testes livre de distribuição.
- Faz suposições sobre o processo gerador dos dados.
- Duas formas de cálculo da estatística de teste:
  - **Exaustiva**: no conjunto de todos os arranjos possíveis
  $\rightarrow$ distribuição amostral exata.
  - **Por reamostragem**: amostra do conjunto completo de arranjos com
    reamostragem sem reposição.
- IMPORTANTE: Sob a hipótese nula os dados são **permutáveis**.
- Esse é o principal conceito e requisito dos testes de
aleatorização.

**Limitações dos testes de aleatorização**

- Só podem ser usados para hipóteses que envolvam comparações
(trocar observações entre grupos) ou desalinhar registros (como em
correlação, por exemplo).
- Portanto, não podem ser usados para testar hipóteses sobre
parâmetros individuais.
- O teste de aleatorização exato de Fisher para a média é uma
alternativa para testar hipótese sobre a média considerando
população simétrica, porém, estritamente não é um teste de
aleatorização.

De acordo com Manly (2006):

- Compara o valor da estatística com aquele obtido da distribuição
gerada pela permutação dos valores observados.
- São úteis pois permitem o usuário definir a estatística de teste
mais apropriada.
- Não necessariamente os resultados podem ser extrapolados para a
população.
- Testes de aleatorização são exatos: fonece um nível de
significância que é igual ou inferior ao nível nominal.
- Duas estatísticas são equivalente se elas dão o mesmo nível de
significância em testes de aleatorização.
- Testes de aleatorização e tradicionais darão similar nível de
significância se as suposições do último forem atendidas.

# Exemplos

## Exemplos simples

### Diferença entre médias de dois grupos

```{r, cache=TRUE}
## Dados observados
x <- c(4.1, 8.3, 2.9, 10.8, 9.5)
y <- c(3.7, 5.1, 1.0, 7.7, 8.9)
da <- data.frame(vals = c(x, y),
                 id = rep(c("x", "y"), each = 5))
da

## Compara médias
with(da, tapply(vals, id, mean))
(obsdiff <- with(da, abs(diff(tapply(vals, id, mean)))))

## Teste-t tradicional
t.test(vals ~ id, data = da, var.equal = TRUE)

## Número possível de permutações por grupo
factorial(length(x))
factorial(length(y))

## A permutação dentro de cada grupo não faz sentido, pois as médias não
## serão alteradas
xperm <- gtools::permutations(n = length(x), r = length(x), v = x)
str(xperm)
sort(x)
head(xperm)
tail(xperm)
yperm <- gtools::permutations(n = length(y), r = length(y), v = y)
str(yperm)
sort(y)
head(yperm)
tail(yperm)
## Diferença entre médias para todas as permutações
xydiff <- numeric(nrow(xperm))
for(i in 1:nrow(xperm)) {
    xydiff[i] <- mean(xperm[i, ]) - mean(yperm[i, ])
}
str(xydiff)
summary(xydiff)

## Portanto, a permutação deve ser feita entre os grupos, ou seja,
## alternando todos os valores possíveis entre os dois grupos
xy <- c(x, y)
## Número de permutações
factorial(length(xy))
xyperm <- gtools::permutations(n = length(xy), r = length(xy), v = xy)
str(xyperm)
sort(xy)
head(xyperm)
tail(xyperm)

## Calcula a diferença média para todas as permutações possíveis
xydiff <- numeric(nrow(xyperm))
for(i in 1:nrow(xyperm)) {
    xydiff[i] <- mean(xyperm[i, 1:5]) - mean(xyperm[i, 6:10])
}
str(xydiff)
summary(xydiff)
hist(xydiff)
abline(v = obsdiff, col = 2)

## P-valor do teste.
2 * sum(xydiff >= obsdiff)/length(xydiff)
t.test(vals ~ id, data = da, var.equal = TRUE)$p.value

## Usando pacotes
library(coin)
oneway_test(vals ~ id, data = da)
oneway_test(vals ~ id, data = da,
            distribution = approximate(nresample = 10000))
library(perm)
permTS(vals ~ id, data = da)

## Mesmo em um caso simples como, esse, onde n = 10, já vimos que o
## número total de permutações possíveis pode ser muito grande, o que
## faz com que esse processo fique inviável computacionalmente.
## A ideia então é fazer um grande número de permutações aleatórias e
## fazer o mesmo cálculo. Isso pode ser feito retirando-se amostra COM
## REPOSIÇÃO da amostra conjunta (concatenando os dois grupos)
## Usando amostras sem reposição
N <- 10000
xydiff <- numeric(N)
for(i in 1:N) {
    xydiff[i] <- diff(tapply(sample(xy), da$id, mean))
}
str(xydiff)
summary(xydiff)
hist(xydiff)
abline(v = obsdiff, col = 2)

## P-valor do teste.
2 * sum(xydiff >= obsdiff)/length(xydiff)
t.test(vals ~ id, data = da, var.equal = TRUE)$p.value
coin::oneway_test(vals ~ id, data = da)
perm::permTS(vals ~ id, data = da)
```

### Teste para correlação

```{r, cache=TRUE}
## Usando o mesmo exemplo, mas agora calculando a correlação entre os
## grupos
## Correlação observada. NOTE que é necessário usar a correlação (de
## postos) de Spearman
cor(x, y, method = "pearson")
cor(x, y, method = "kendall")
(obscor <- cor(x, y, method = "spearman"))

## Calcula a diferença média para todas as permutações possíveis
xycor <- numeric(nrow(xyperm))
for(i in 1:nrow(xyperm)) {
    xycor[i] <- cor(xyperm[i, 1:5], xyperm[i, 6:10],
                    method = "spearman")
}
str(xycor)
summary(xycor)
hist(xycor)
abline(v = obscor, col = 2)

## P-valor do teste.
2 * sum(xycor >= obscor)/length(xycor) # teste exato
cor.test(x, y,  method = "pearson")$p.value
cor.test(x, y,  method = "kendall")$p.value
cor.test(x, y,  method = "spearman")$p.value
spearman_test(x ~ y,
              distribution = approximate(nresample = 10000))

## Usa amostragem SEM REPOSIÇÃO
N <- 100000
n <- length(xy)
xycor <- numeric(N)
for(i in 1:N) {
    ip <- sample(1:n, replace = FALSE)
    xp <- xy[ip[1:5]]
    yp <- xy[ip[6:10]]
    xycor[i] <- cor(xp, yp, method = "spearman")
}
str(xycor)
summary(xycor)
hist(xycor)
abline(v = obscor, col = 2)

## P-valor do teste.
2 * sum(xycor >= obscor)/length(xycor) # teste aproximado
cor.test(x, y,  method = "pearson")$p.value
cor.test(x, y,  method = "kendall")$p.value
cor.test(x, y,  method = "spearman")$p.value
spearman_test(x ~ y,
              distribution = approximate(nresample = 10000))
```

## Exemplo aplicado: correlação

```{r, cache=TRUE}
data(law, package = "bootstrap")
str(law)
plot(law$LSAT, law$GPA)
x <- law$LSAT
y <- law$GPA
(obscor <- cor(x, y, method = "spearman"))

## Impossível fazer com todas as permutações
factorial(nrow(law))

## Usa amostragem SEM REPOSIÇÃO
N <- 1000000
xy <- c(x, y)
n <- length(xy)
xycor <- numeric(N)
for(i in 1:N) {
    ip <- sample(1:n, size = n/2, replace = FALSE)
    xp <- xy[ip]
    yp <- xy[-ip]
    xycor[i] <- cor(xp, yp, method = "spearman")
}
str(xycor)
summary(xycor)
hist(xycor)
abline(v = obscor, col = 2)

## P-valor do teste.
2 * sum(xycor >= obscor)/length(xycor) # teste aproximado
cor.test(x, y,  method = "pearson")$p.value
cor.test(x, y,  method = "kendall")$p.value
cor.test(x, y,  method = "spearman")$p.value
spearman_test(x ~ y,
              distribution = approximate(nresample = 100000))
```

## Exemplo das aulas anteriores

```{r}
## Exemplo adaptado de Manly (1997)
## Comparação do comprimento da mandíbula de chacais machos e fêmeas
set.seed(2)
machos <- c(120, 107, 110, 116, 114, 111, 113, 117, 114, 112)
## Simula diferença para as femeas
femeas <- rnorm(10, mean(machos) - 2, sd = sd(machos))
da <- data.frame(comp = c(machos, femeas),
                 sexo = c(rep("M", 10), rep("F", 10)))
densityplot(~comp, groups = sexo, data = da, auto.key = TRUE)
## Média por sexo
tapply(da$comp, da$sexo, mean)
## Diferença das médias
diff(tapply(da$comp, da$sexo, mean))

## Média de cada sexo
(m1 <- mean(machos))
(m2 <- mean(femeas))
## Diferença entre as médias amostrais
(med.amostral <- m1 - m2)
## Calcula o desvio padrão ponderado
n1 <- length(machos)
v1 <- var(machos)
n2 <- length(femeas)
v2 <- var(femeas)
(s.pond <- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2)/(n1 + n2 - 2)))

## Teste de hipótese para
## H0: mu1 <= mu2
## Ha: mu1 > mu2
mu0 <- 0
t.test(x = machos, y = femeas, alternative = "greater",
       var.equal = TRUE, mu = mu0)
## Estatística de teste
(tcalc <- (m1 - m2)/(s.pond * sqrt(1/n1 + 1/n2)))
## Valor crítico
(tcrit <- qt(.025, df = n1 + n2 - 2, lower.tail = FALSE))
## p-valor
pt(tcalc, df = n1 + n2 - 2, lower.tail = FALSE)

## Teste por simulação via _permutação_
N <- 10000
## Se a hipótese nula é verdadeira, então o comprimento das mandíbulas
## de machos e fêmeas são provenientes da mesma poplação, e portanto
## podem ser pensados como uma única amostra.
amostra <- c(machos, femeas)
## Amostra SEM REPOSIÇÃO os 20 valores, e atribui aleatoriamente 10 para
## cada grupo (macho ou fêmea). Se forem de fato da mesma população,
## então as diferenças entre as médias devem ser próximas de zero.
am <- replicate(
    N, diff(tapply(sample(amostra, replace = FALSE), da$sexo, mean))
)
## Visualização
hist(am, main = "Distribuição amostral")
abline(v = med.amostral, col = 2)
## p-valor empírico
sum(am >= med.amostral)/N
```

```{r}
## Exemplo adaptado de Manly (1997)
## Comparação do comprimento da mandíbula de chacais machos e fêmeas
machos <- c(120, 107, 110, 116, 114, 111, 113, 117, 114, 112)
femeas <- c(110, 111, 107, 108, 110, 105, 107, 106, 111, 111)
da <- data.frame(comp = c(machos, femeas),
                 sexo = c(rep("M", 10), rep("F", 10)))
densityplot(~comp, groups = sexo, data = da, auto.key = TRUE)
## Média por sexo
tapply(da$comp, da$sexo, mean)
## Diferença das médias
diff(tapply(da$comp, da$sexo, mean))

## Média de cada sexo
(m1 <- mean(machos))
(m2 <- mean(femeas))
## Diferença entre as médias amostrais
(med.amostral <- m1 - m2)
## Calcula o desvio padrão ponderado
n1 <- length(machos)
v1 <- var(machos)
n2 <- length(femeas)
v2 <- var(femeas)
(s.pond <- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2)/(n1 + n2 - 2)))

## Teste de hipótese para
## H0: mu1 <= mu2
## Ha: mu1 > mu2
mu0 <- 0
t.test(x = machos, y = femeas, alternative = "greater",
       var.equal = TRUE, mu = mu0)
## Estatística de teste
(tcalc <- (m1 - m2)/(s.pond * sqrt(1/n1 + 1/n2)))
## Valor crítico
(tcrit <- qt(.025, df = n1 + n2 - 2, lower.tail = FALSE))
## p-valor
pt(tcalc, df = n1 + n2 - 2, lower.tail = FALSE)

## Teste por simulação via _permutação_
N <- 10000
## Se a hipótese nula é verdadeira, então o comprimento das mandíbulas
## de machos e fêmeas são provenientes da mesma população, e portanto
## podem ser pensados como uma única amostra.
amostra <- c(machos, femeas)
## Amostra SEM REPOSIÇÃO os 20 valores, e atribui aleatoriamente 10 para
## cada grupo (macho ou fêmea). Se forem de fato da mesma população,
## então as diferenças entre as médias devem ser próximas de zero.
am <- replicate(
    N, diff(tapply(sample(amostra, replace = FALSE), da$sexo, mean))
)
## Visualização
hist(am, main = "Distribuição amostral")
abline(v = med.amostral, col = 2)
## p-valor empírico
sum(am >= med.amostral)/N
```


```{r, include=FALSE, eval=FALSE}
x <- 1:8 # x-coordinates of points
y <- 1:5 # y-coordinates of points
#
# Weights matrix.
#
## The weights are proportional to 1 for cells that share a side, to
## sqrt(1/2) = 0.7071 for cells that only share a corner, and to 0
## otherwise.
ind <- expand.grid(i=1:length(x), j=1:length(y))
f <- function(i, j) {
  u <- min(3, sum(abs(ind[i, ] - ind[j, ])))
  c(0, 1, sqrt(1/2), 0)[u+1]
}
w <- matrix(0.0, nrow(ind), nrow(ind))
for (i in 1:nrow(ind)) for (j in 1:nrow(ind)) w[i,j] <- f(i,j)
image(w)
w <- w / sum(w)
image(w)
#
# Moran's I.
#
moran <- function(x, weights) {
  n <- length(x)
  z <- as.vector((x - mean(x)) / sd(x))
  as.vector(z %*% weights %*% (z * sqrt(n / (n-1))))
}
#
# Permutation test (including a plot).
#
ppt <- function(z, w, N=1e4, ...) {
  stat <- moran(z, w)
  sim <- replicate(N, moran(sample(z, length(z)), w))
  p.value <- mean((all <- c(stat, sim)) >= stat)
  hist(sim, sub=paste("p =", round(p.value, 4)), xlim=range(all), ...)
  abline(v = stat, col="#903030", lty=3, lwd=2)
  return(p.value)
}
#
# Simulated observations.
#
set.seed(17)
par(mfrow=c(2,3))

# Induce autocorrelation via an underlying trend.
z <- matrix(rexp(length(x)*length(y), outer(x,y^2)), length(x))
image(log(z), main="Autocorrelated Data")
hist(z)
ppt(z, w, main="Null Distribution of Moran's I", xlab="I")

# Generate data independently of location.
z <- matrix(rnorm(length(x)*length(y), 0, 1/2), length(x))
image(z, main="Uncorrelated Data")
hist(z)
ppt(z, w, main="Null Distribution of Moran's I", xlab="I")
```
