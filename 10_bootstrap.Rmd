---
title: "Métodos de reamostragem"
subtitle: "Bootstrap (não paramétrico)"
author: "Fernando P. Mayer"
bibliography: ref.bib
output:
  html_document:
    number_sections: true
    toc_depth: 3
---

```{r, cache=FALSE, include=FALSE}
source("setup_knitr.R")
opts_chunk$set(fig.path = "figures/10_bootstrap/")
```

# Introdução

- Os métodos de Bootstrap são uma classe de métodos de Monte Carlo não
paramétricos, que estimam a distribuição de uma população por
reamostragem

- Métodos de reamostragem tratam a amostra observada como uma população
  finita
  - A distribuição da população finita representada pela amostra
  observada, pode ser pode ser entendida como uma pseudo-população, com
  características similares às da população original

- Amostra aleatórias são geradas (reamostragem) a partir da amostra
  original, para estimar características populacionais e fazer
  inferência sobre a população amostrada
  - Através da reamostragem, a distribuição amostral de uma estatística
    pode ser estimada, e as propriedades de um estimador podem então ser
    calculadas através do erro padrão e cálculos de viés

- Métodos de bootstrap são utilizados quando a distribuição da população
  alvo não é especificada (ou conhecida), e a amsotra é a única
  informação disponível

**Justificativas**

- Métodos computacionalmente intensivos para inferência
estatística são usados quando as abordagens tradicionais não são
adequadas.
- Resultados assintóticos em pequenas amostras.
- Violação de pressupostos.
- Não existência de mecanísmos de inferência específicos.
- Tais métodos se baseiam em reamostragem e/ou simulação.
- Podem ser aplicados em muitos contextos.

**Bootstrap: visão geral**

- Boostrap foi apresentado de forma sistematizada por Efron (1979).
- O termo bootstrap foi usado por Efron (1979) com o mesmo espírito que
  Tukey (1958) usou Jackknife (canivete suiço)
- O método já havia sido usado em circustâncias anteriores.
- Bootstrap é um **método de reamostragem** que pode usado para
avaliar propriedades de estimadores e fazer inferência.
- Bootstrap é um método de Monte Carlo pois usa a **distribuição
empírica** dos dados como se fosse a verdadeira distribuição.
- Principais aplicações de bootstrap:
  - Avaliar propriedades da distribuição de estimadores para
  seleção, ajuste de vício, etc.
  - Substituir ou aprimorar a adequação de abordagens assintóticas em
  amostras pequenas: intervalos de confiança, testes de hipótese.

**Funcionamento**

- Considere uma amostra de observações iid $x_i$, $i = 1, \ldots, n$
- Usando a distribuição empírica, cada valor $x_i$ tem igual
probabilidade $1/n$ de ocorrer.
- Considere que $\theta$ seja um parâmetro de interesse que dispõe
de um estimador $\hat{\theta} = f(X_1, ..., X_n)$.
- Uma **amostra bootstrap** é um conjunto de valores extraídos ao
acaso **com reposição** da amostra original.
- A estimativa de $\theta$ na $b$-ésima reamostra bootstrap é
$\hat{\theta}^{b}$.

**Algoritmo**

Para cada estimativa de bootstrap indexada $b = 1, \ldots, B$:

1. Gere uma amostra $x^{\star} = (x_1^{\star}, \ldots, x_n^{\star})$,
através de amostragem **com reposição** de amostra observada $x_1,
\ldots, x_n$
2. Calcule a $b$-ésima estimativa $\hat{\theta}^{(b)}$ da $b$-ésima
amostra de bootstrap

A estimativa pontual bootstrap é o valor médio
$$
\overline{\hat{\theta}^\star} = \frac{1}{B} \sum_{b = 1}^{B}
\hat{\theta}^{(b)}
$$

### Exemplo da aula anterior {-}

```{r}
## Exemplo adaptado de Manly (1997)
## Comparação do comprimento da mandíbula de chacais machos e fêmeas
set.seed(2)
machos <- c(120, 107, 110, 116, 114, 111, 113, 117, 114, 112)
## Simula diferença para as femeas
femeas <- rnorm(10, mean(machos) - 2, sd = sd(machos))
da <- data.frame(comp = c(machos, femeas),
                 sexo = c(rep("M", 10), rep("F", 10)))
densityplot(~comp, groups = sexo, data = da, auto.key = TRUE)
## Média por sexo
tapply(da$comp, da$sexo, mean)
## Diferença das médias
diff(tapply(da$comp, da$sexo, mean))

## Média de cada sexo
(m1 <- mean(machos))
(m2 <- mean(femeas))
## Diferença entre as médias amostrais
(med.amostral <- m1 - m2)
## Calcula o desvio padrão ponderado
n1 <- length(machos)
v1 <- var(machos)
n2 <- length(femeas)
v2 <- var(femeas)
(s.pond <- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2)/(n1 + n2 - 2)))

## Teste de hipótese para
## H0: mu1 <= mu2
## Ha: mu1 > mu2
mu0 <- 0
t.test(x = machos, y = femeas, alternative = "greater",
       var.equal = TRUE, mu = mu0)
## Estatística de teste
(tcalc <- (m1 - m2)/(s.pond * sqrt(1/n1 + 1/n2)))
## Valor crítico
(tcrit <- qt(.025, df = n1 + n2 - 2, lower.tail = FALSE))
## p-valor
pt(tcalc, df = n1 + n2 - 2, lower.tail = FALSE)

## Teste por simulação via Bootstrap
N <- 10000
## Se a hipótese nula é verdadeira, então o comprimento das mandíbulas
## de machos e fêmeas são provenientes da mesma poplação, e portanto
## podem ser pensados como uma única amostra.
amostra <- c(machos, femeas)
## Amostra COM REPOSIÇÃO os 20 valores, e atribui aleatoriamente 10 para
## cada grupo (macho ou fêmea). Se forem de fato da mesma população,
## então as diferenças entre as médias devem ser próximas de zero.
am <- replicate(
    N, diff(tapply(sample(amostra, replace = TRUE), da$sexo, mean))
)
## Visualização
hist(am, main = "Distribuição amostral")
abline(v = med.amostral, col = 2)
## p-valor empírico
sum(am >= med.amostral)/N
```

```{r}
## Exemplo adaptado de Manly (1997)
## Comparação do comprimento da mandíbula de chacais machos e fêmeas
machos <- c(120, 107, 110, 116, 114, 111, 113, 117, 114, 112)
femeas <- c(110, 111, 107, 108, 110, 105, 107, 106, 111, 111)
da <- data.frame(comp = c(machos, femeas),
                 sexo = c(rep("M", 10), rep("F", 10)))
densityplot(~comp, groups = sexo, data = da, auto.key = TRUE)
## Média por sexo
tapply(da$comp, da$sexo, mean)
## Diferença das médias
diff(tapply(da$comp, da$sexo, mean))

## Média de cada sexo
(m1 <- mean(machos))
(m2 <- mean(femeas))
## Diferença entre as médias amostrais
(med.amostral <- m1 - m2)
## Calcula o desvio padrão ponderado
n1 <- length(machos)
v1 <- var(machos)
n2 <- length(femeas)
v2 <- var(femeas)
(s.pond <- sqrt(((n1 - 1) * v1 + (n2 - 1) * v2)/(n1 + n2 - 2)))

## Teste de hipótese para
## H0: mu1 <= mu2
## Ha: mu1 > mu2
mu0 <- 0
t.test(x = machos, y = femeas, alternative = "greater",
       var.equal = TRUE, mu = mu0)
## Estatística de teste
(tcalc <- (m1 - m2)/(s.pond * sqrt(1/n1 + 1/n2)))
## Valor crítico
(tcrit <- qt(.025, df = n1 + n2 - 2, lower.tail = FALSE))
## p-valor
pt(tcalc, df = n1 + n2 - 2, lower.tail = FALSE)

## Teste por simulação via Bootstrap
N <- 10000
## Se a hipótese nula é verdadeira, então o comprimento das mandíbulas
## de machos e fêmeas são provenientes da mesma poplação, e portanto
## podem ser pensados como uma única amostra.
amostra <- c(machos, femeas)
## Amostra COM REPOSIÇÃO os 20 valores, e atribui aleatoriamente 10 para
## cada grupo (macho ou fêmea). Se forem de fato da mesma população,
## então as diferenças entre as médias devem ser próximas de zero.
am <- replicate(
    N, diff(tapply(sample(amostra, replace = TRUE), da$sexo, mean))
)
## Visualização
hist(am, main = "Distribuição amostral")
abline(v = med.amostral, col = 2)
## p-valor empírico
sum(am >= med.amostral)/N
```

### Uma nota de precaução {-}

```{r}
## Amostra de uma Poisson(2)
x <- c(2, 2, 1, 1, 5, 4, 4, 3, 1, 2)
## Distribuição empírica
prop.table(table(x))
## Distribuição empírica acumulada
cumsum(prop.table(table(x)))

## Amostra via bootstrap
## Um passo
am <- sample(x, replace = TRUE)
prop.table(table(am))
cumsum(prop.table(table(am)))

## B passos
B <- 1000
am <- sample(x, size = B, replace = TRUE)
prop.table(table(am))
cumsum(prop.table(table(am)))

## Qual o problema então?
## Distribuição empírica
plot(0:5, c(0, prop.table(table(am))), type = "h")
## Distribuição teórica
points((0:5) + .1, dpois(0:5, 2), type = "h", col = 2)
```

# Estimativa de erro padrão via bootstrap

A estimativa do erro padrão de um estimador $\hat{\theta}$ via bootstrap
é o desvio padrão amostral das estimativas de bootstrap
$\hat{\theta}^{(1)}, \ldots, \hat{\theta}^{(B)}$

$$
se(\hat{\theta}^{\star}) = \sqrt{\frac{1}{B-1}
\sum_{b=1}^{B} (\hat{\theta}^{(b)} - \overline{\hat{\theta}^{\star}})}
$$

```{r}
## Estimativa de erro padrão via bootstrap
library(bootstrap) # para carregar os dados
## Uma amostra dos dados originais
str(law)
plot(law$LSAT, law$GPA)
cor(law$LSAT, law$GPA)
## Dados originais
str(law82)
plot(law82$LSAT, law82$GPA)
cor(law82$LSAT, law82$GPA)

## Definições
B <- 200
n <- nrow(law)
R <- numeric(B)

## Bootstrap para a estimativa do erro padrão do R (correlação amostral)
for (b in 1:B) {
    i <- sample(1:n, size = n, replace = TRUE)
    LSAT <- law$LSAT[i]
    GPA <- law$GPA[i]
    R[b] <- cor(LSAT, GPA)
}

## Resultado
mean(R)
(se.R <- sd(R))
hist(R)
```

```{r}
## Usando a função boot::boot()

## Define a função que calcula a estatística de interesse
r <- function(x, i) {
    cor(x[i, 1], x[i, 2])
}

## Roda o processo
library(boot)
obj <- boot(data = law, statistic = r, R = 2000)
obj
str(obj)
plot(obj)

## Acessa os valores calculados
y <- as.vector(obj$t)
mean(y)
sd(y)
```

```{r}
## Usando a função bootstrap::bootstrap()

## Define a função que calcula a estatística
r <- function(x, xdata) {
    cor(xdata[x, 1], xdata[x, 2])
}

## Procedimento
n <- nrow(law)
obj2 <- bootstrap(x = 1:n, nboot = 2000, theta = r, law)
mean(obj2$thetastar)
sd(obj2$thetastar)
```

# Estimativa do viés via bootstrap

Se $\hat{\theta}$ é um estimador não viesado para $\theta$, então
$\text{E}[\hat{\theta}] = \theta$. O viés de um estimador
$\hat{\theta}$ de $\theta$ é

$$
\text{B}[\hat{\theta}] = \text{E}[\hat{\theta} - \theta] =
\text{E}[\hat{\theta}] - \theta
$$

- A estimativa de viés via bootstrap usa as estimativas de bootstrap de
$\hat{\theta}$ para construir a distribuição amostral de $\hat{\theta}$.

- Para a população finita $x = (x_1, \ldots, x_n)$, o parâmetro é
$\hat{\theta}(x)$, e existem $B$ estimativas $\hat{\theta}^{(b)}$
independentes e identicamente distribuídas.

- A média amostral de $\{\hat{\theta}^{(b)}\}$ é não viesada para o
  valor esperado $\text{E}[\hat{\theta}^{\star}]$, então a estimativa de
  viés via bootsrap é
$$
\widehat{\text{B}}[\hat{\theta}] = \overline{\hat{\theta}^{\star}} -
  \hat{\theta}
$$
onde $\hat{\theta} = \hat{\theta}(x)$ é a estimativa calculada da
  amostra original.

- Valores positivos de viés indicam que, em média, \hat{\theta} tende a
  sobrestimar $\theta$.


```{r}
## Estimativa do viés via bootstrap

## Estatística amostral
(theta.hat <- cor(law$LSAT, law$GPA))

## Definições
B <- 2000
n <- nrow(law)
theta.b <- numeric(B)

for (b in 1:B) {
    i <- sample(1:n, size = n, replace = TRUE)
    LSAT <- law$LSAT[i]
    GPA <- law$GPA[i]
    theta.b[b] <- cor(LSAT, GPA)
}

## Viés
mean(theta.b) - theta.hat
```

# Intervalos de confiança via Bootstrap

```{r}
### Example 8.5 (Bootstrap estimate of bias of a ratio estimate)
data(patch, package = "bootstrap")
patch

n <- nrow(patch)  #in bootstrap package
B <- 2000
theta.b <- numeric(B)
theta.hat <- mean(patch$y) / mean(patch$z)

                                        #bootstrap
for (b in 1:B) {
    i <- sample(1:n, size = n, replace = TRUE)
    y <- patch$y[i]
    z <- patch$z[i]
    theta.b[b] <- mean(y) / mean(z)
}
bias <- mean(theta.b) - theta.hat
se <- sd(theta.b)
print(list(est=theta.hat, bias = bias,
           se = se, cv = bias/se))
```

```{r}
### Example 8.9 (Bootstrap confidence intervals for patch ratio statistic)

library(boot)       #for boot and boot.ci
data(patch, package = "bootstrap")

theta.boot <- function(dat, ind) {
                                        #function to compute the statistic
    y <- dat[ind, 1]
    z <- dat[ind, 2]
    mean(y) / mean(z)
    }

y <- patch$y
z <- patch$z
dat <- cbind(y, z)
boot.obj <- boot(dat, statistic = theta.boot, R = 2000)

print(boot.obj)
print(boot.ci(boot.obj,
              type = c("basic", "norm", "perc")))


                                        #calculations for bootstrap confidence intervals
alpha <- c(.025, .975)

                                        #normal
print(boot.obj$t0 + qnorm(alpha) * sd(boot.obj$t))

                                        #basic
print(2*boot.obj$t0 -
      quantile(boot.obj$t, rev(alpha), type=1))

                                        #percentile
print(quantile(boot.obj$t, alpha, type=6))


### Example 8.10 (Bootstrap confidence intervals for the correlation
### statistic)

library(boot)
data(law, package = "bootstrap")
boot.obj <- boot(law, R = 2000,
                 statistic = function(x, i){cor(x[i,1], x[i,2])})
print(boot.ci(boot.obj, type=c("basic","norm","perc")))


### Example 8.11 (Bootstrap t confidence interval)

boot.t.ci <-
    function(x, B = 500, R = 100, level = .95, statistic){
                                        #compute the bootstrap t CI
        x <- as.matrix(x);  n <- nrow(x)
        stat <- numeric(B); se <- numeric(B)

        boot.se <- function(x, R, f) {
                                        #local function to compute the
                                        #bootstrap
                                        #estimate of standard error for statistic f(x)
            x <- as.matrix(x); m <- nrow(x)
            th <- replicate(R, expr = {
                i <- sample(1:m, size = m, replace = TRUE)
                f(x[i, ])
            })
            return(sd(th))
        }

        for (b in 1:B) {
            j <- sample(1:n, size = n, replace = TRUE)
            y <- x[j, ]
            stat[b] <- statistic(y)
            se[b] <- boot.se(y, R = R, f = statistic)
        }
        stat0 <- statistic(x)
        t.stats <- (stat - stat0) / se
        se0 <- sd(stat)
        alpha <- 1 - level
        Qt <- quantile(t.stats, c(alpha/2, 1-alpha/2), type = 1)
        names(Qt) <- rev(names(Qt))
        CI <- rev(stat0 - Qt * se0)
    }


### Example 8.12 (Bootstrap t confidence interval for patch ratio statistic)

    #boot package and patch data were loaded in Example 8.10
    #library(boot)       #for boot and boot.ci
    #data(patch, package = "bootstrap")

dat <- cbind(patch$y, patch$z)
stat <- function(dat) {
    mean(dat[, 1]) / mean(dat[, 2]) }
ci <- boot.t.ci(dat, statistic = stat, B=2000, R=200)
print(ci)
```
